{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import operator\n",
    "import math\n",
    "from datetime import timedelta \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.max_columns = None\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtparser (x): \n",
    "    try:\n",
    "        return pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    except ValueError:\n",
    "        return pd.datetime.strptime(x, '%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('input/out.csv', lineterminator='\\n',  parse_dates=['signup_time', 'tweet_created_at' ], date_parser=dtparser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>location</th>\n",
       "      <th>verified</th>\n",
       "      <th>user_description</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>listed_count.1</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>tweet_content_text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>371043472397987841</td>\n",
       "      <td>16436153</td>\n",
       "      <td>michaelcorcoran</td>\n",
       "      <td>2008-09-24 15:57:12</td>\n",
       "      <td>3787</td>\n",
       "      <td>2037</td>\n",
       "      <td>Mediocre, TX</td>\n",
       "      <td>False</td>\n",
       "      <td>Opinions on everything, but only an authority ...</td>\n",
       "      <td>135</td>\n",
       "      <td>344</td>\n",
       "      <td>10898</td>\n",
       "      <td>False</td>\n",
       "      <td>135</td>\n",
       "      <td>2013-08-23 22:57:12</td>\n",
       "      <td>San Diego mayor resigns amid sexual harassment...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>371043478404222976</td>\n",
       "      <td>43337221</td>\n",
       "      <td>MrJaredBarnes</td>\n",
       "      <td>2009-05-29 14:17:51</td>\n",
       "      <td>456</td>\n",
       "      <td>335</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>False</td>\n",
       "      <td>Im here for a good time not a long time</td>\n",
       "      <td>16</td>\n",
       "      <td>7648</td>\n",
       "      <td>55759</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>2013-08-23 22:57:13</td>\n",
       "      <td>RT @CNN: San Diego mayor resigns after sexual ...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>371043512642719744</td>\n",
       "      <td>343055758</td>\n",
       "      <td>wrigleylemons</td>\n",
       "      <td>2011-07-27 00:30:14</td>\n",
       "      <td>59</td>\n",
       "      <td>102</td>\n",
       "      <td>Here and there</td>\n",
       "      <td>False</td>\n",
       "      <td>Attatchment leads to jealousy</td>\n",
       "      <td>0</td>\n",
       "      <td>1487</td>\n",
       "      <td>2257</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-23 22:57:21</td>\n",
       "      <td>Bye                       ‚Äú@CNN: San Diego may...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.710414e+17</td>\n",
       "      <td>759251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>371043526026752000</td>\n",
       "      <td>456094924</td>\n",
       "      <td>runbaileyrun_</td>\n",
       "      <td>2012-01-05 21:32:38</td>\n",
       "      <td>616</td>\n",
       "      <td>557</td>\n",
       "      <td>WILMINGTON MA</td>\n",
       "      <td>False</td>\n",
       "      <td>‚Ä¢ You are crazy, my child. You must go to Berl...</td>\n",
       "      <td>8</td>\n",
       "      <td>24907</td>\n",
       "      <td>16382</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-23 22:57:24</td>\n",
       "      <td>RT @BostonGlobe: BREAKING: Embattled San Diego...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>371043523262312448</td>\n",
       "      <td>205143160</td>\n",
       "      <td>JamesVal70</td>\n",
       "      <td>2010-10-20 07:20:06</td>\n",
       "      <td>4980</td>\n",
       "      <td>5419</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>False</td>\n",
       "      <td>Christian, Father, Musician,Independent - #The...</td>\n",
       "      <td>98</td>\n",
       "      <td>3722</td>\n",
       "      <td>23834</td>\n",
       "      <td>False</td>\n",
       "      <td>98</td>\n",
       "      <td>2013-08-23 22:57:24</td>\n",
       "      <td>V.CNN BREAKING San Diego City Council accepts ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>371043530598150145</td>\n",
       "      <td>19266265</td>\n",
       "      <td>twocitylife</td>\n",
       "      <td>2009-01-21 00:10:00</td>\n",
       "      <td>1140</td>\n",
       "      <td>1129</td>\n",
       "      <td>San Diego / Palm Desert</td>\n",
       "      <td>False</td>\n",
       "      <td>Curator / Journalist</td>\n",
       "      <td>71</td>\n",
       "      <td>13585</td>\n",
       "      <td>18699</td>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>2013-08-23 22:57:26</td>\n",
       "      <td>RT @citybeatkelly: So, despite therapy, Filner...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>371043543373975552</td>\n",
       "      <td>489647114</td>\n",
       "      <td>popleibel</td>\n",
       "      <td>2012-02-11 18:56:14</td>\n",
       "      <td>2697</td>\n",
       "      <td>2069</td>\n",
       "      <td>Punta Arenas, Chile</td>\n",
       "      <td>False</td>\n",
       "      <td>Entre mis recuerdos audi√≥filos m√°s tempranos (...</td>\n",
       "      <td>199</td>\n",
       "      <td>340931</td>\n",
       "      <td>371901</td>\n",
       "      <td>False</td>\n",
       "      <td>199</td>\n",
       "      <td>2013-08-23 22:57:29</td>\n",
       "      <td>RT @WSJ: Breaking: San Diego Mayor Bob Filner ...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>371043558095982595</td>\n",
       "      <td>37018152</td>\n",
       "      <td>james_laker</td>\n",
       "      <td>2009-05-01 19:23:26</td>\n",
       "      <td>5172</td>\n",
       "      <td>3948</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>False</td>\n",
       "      <td>No matter the opponents Game Man Listens Own O...</td>\n",
       "      <td>120</td>\n",
       "      <td>22</td>\n",
       "      <td>274838</td>\n",
       "      <td>False</td>\n",
       "      <td>120</td>\n",
       "      <td>2013-08-23 22:57:32</td>\n",
       "      <td>RT @Yahoo: UPDATE: San Diego Mayor #BobFilner ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>371043556225318912</td>\n",
       "      <td>305223472</td>\n",
       "      <td>LaurenSteussy</td>\n",
       "      <td>2011-05-25 21:13:16</td>\n",
       "      <td>1885</td>\n",
       "      <td>2651</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>False</td>\n",
       "      <td>Features reporter/editor at the New York Post,...</td>\n",
       "      <td>75</td>\n",
       "      <td>1753</td>\n",
       "      <td>4964</td>\n",
       "      <td>False</td>\n",
       "      <td>75</td>\n",
       "      <td>2013-08-23 22:57:32</td>\n",
       "      <td>RT @citybeatkelly: So, despite therapy, Filner...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>371043567520595968</td>\n",
       "      <td>250378882</td>\n",
       "      <td>eddiekimx</td>\n",
       "      <td>2011-02-11 00:01:49</td>\n",
       "      <td>1520</td>\n",
       "      <td>1398</td>\n",
       "      <td>Los Angeles, Calif.</td>\n",
       "      <td>False</td>\n",
       "      <td>Writing features for @WeAreMel. Seen/heard in ...</td>\n",
       "      <td>90</td>\n",
       "      <td>9514</td>\n",
       "      <td>18624</td>\n",
       "      <td>False</td>\n",
       "      <td>90</td>\n",
       "      <td>2013-08-23 22:57:34</td>\n",
       "      <td>RT @BostonGlobe: BREAKING: Embattled San Diego...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>371043568896733184</td>\n",
       "      <td>581168201</td>\n",
       "      <td>PhilipAMonteiro</td>\n",
       "      <td>2012-05-15 19:16:23</td>\n",
       "      <td>558</td>\n",
       "      <td>470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Law student. Civil Air Patrol officer. Trumpet...</td>\n",
       "      <td>5</td>\n",
       "      <td>160746</td>\n",
       "      <td>10283</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-08-23 22:57:35</td>\n",
       "      <td>RT @BBCBreaking: San Diego Mayor Bob Filner qu...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>371043589054144513</td>\n",
       "      <td>22025982</td>\n",
       "      <td>RoshiniR</td>\n",
       "      <td>2009-02-26 16:11:28</td>\n",
       "      <td>4849</td>\n",
       "      <td>4148</td>\n",
       "      <td>Global Citizen</td>\n",
       "      <td>False</td>\n",
       "      <td>Crisis Coach; @WCCORadio Host; Media Analyst; ...</td>\n",
       "      <td>221</td>\n",
       "      <td>8761</td>\n",
       "      <td>20800</td>\n",
       "      <td>False</td>\n",
       "      <td>221</td>\n",
       "      <td>2013-08-23 22:57:39</td>\n",
       "      <td>RT @BostonGlobe: BREAKING: Embattled San Diego...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>371043589930762240</td>\n",
       "      <td>23217897</td>\n",
       "      <td>dardar1126</td>\n",
       "      <td>2009-03-07 18:15:57</td>\n",
       "      <td>770</td>\n",
       "      <td>459</td>\n",
       "      <td>Texas</td>\n",
       "      <td>False</td>\n",
       "      <td>Perpetual student of life*pro-equal rights for...</td>\n",
       "      <td>109</td>\n",
       "      <td>31173</td>\n",
       "      <td>272201</td>\n",
       "      <td>True</td>\n",
       "      <td>109</td>\n",
       "      <td>2013-08-23 22:57:40</td>\n",
       "      <td>RT @BostonGlobe: BREAKING: Embattled San Diego...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>371043625431339008</td>\n",
       "      <td>8010462</td>\n",
       "      <td>randyjohnston</td>\n",
       "      <td>2007-08-07 03:13:08</td>\n",
       "      <td>1011</td>\n",
       "      <td>930</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>False</td>\n",
       "      <td>Views mine. RTs not endorsements. Yadda yadda...</td>\n",
       "      <td>25</td>\n",
       "      <td>2767</td>\n",
       "      <td>6039</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-23 22:57:48</td>\n",
       "      <td>RT @BostonGlobe: BREAKING: Embattled San Diego...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>371043634151718912</td>\n",
       "      <td>264307945</td>\n",
       "      <td>FixingNewsRjcts</td>\n",
       "      <td>2011-03-11 17:51:18</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Messages rejected by @FixingNews</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20322</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-08-23 22:57:50</td>\n",
       "      <td>RT @BBCBreaking: San Diego mayor Bob Filner an...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>371043637892632576</td>\n",
       "      <td>43023750</td>\n",
       "      <td>megcglass</td>\n",
       "      <td>2009-05-28 02:09:18</td>\n",
       "      <td>308</td>\n",
       "      <td>887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>likes stuff. enjoys the san diego sun.</td>\n",
       "      <td>16</td>\n",
       "      <td>22803</td>\n",
       "      <td>96434</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>2013-08-23 22:57:51</td>\n",
       "      <td>RT @BostonGlobe: BREAKING: Embattled San Diego...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>371043640065286144</td>\n",
       "      <td>73800348</td>\n",
       "      <td>ryukan2</td>\n",
       "      <td>2009-09-13 03:13:53</td>\n",
       "      <td>422</td>\n",
       "      <td>383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>6530</td>\n",
       "      <td>60696</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>2013-08-23 22:57:52</td>\n",
       "      <td>Bob Filner Resigns: San Diego Mayor Agrees To ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>371043648768450560</td>\n",
       "      <td>106551925</td>\n",
       "      <td>Marco_NY23</td>\n",
       "      <td>2010-01-19 23:01:05</td>\n",
       "      <td>2737</td>\n",
       "      <td>4120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PR &amp; Corp. Comms, Journalist &amp; Storyteller | P...</td>\n",
       "      <td>656</td>\n",
       "      <td>5599</td>\n",
       "      <td>82629</td>\n",
       "      <td>False</td>\n",
       "      <td>656</td>\n",
       "      <td>2013-08-23 22:57:54</td>\n",
       "      <td>RT @WSJ: Breaking: San Diego Mayor Bob Filner ...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>371043665248284672</td>\n",
       "      <td>155329660</td>\n",
       "      <td>tony_manna</td>\n",
       "      <td>2010-06-13 20:56:20</td>\n",
       "      <td>5754</td>\n",
       "      <td>6925</td>\n",
       "      <td>Florida-Man</td>\n",
       "      <td>False</td>\n",
       "      <td>I organize noise- #Conservatarian ChristianŸÜ &amp;...</td>\n",
       "      <td>91</td>\n",
       "      <td>3489</td>\n",
       "      <td>16987</td>\n",
       "      <td>False</td>\n",
       "      <td>91</td>\n",
       "      <td>2013-08-23 22:57:58</td>\n",
       "      <td>#WarOnWomen -Not only will the gov pay for all...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>371043666212552704</td>\n",
       "      <td>15412641</td>\n",
       "      <td>TimmyShea</td>\n",
       "      <td>2008-07-13 06:40:55</td>\n",
       "      <td>1517</td>\n",
       "      <td>1216</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>False</td>\n",
       "      <td>NY, by way of DC. ‚úàÔ∏è. Technology, infrastructu...</td>\n",
       "      <td>64</td>\n",
       "      <td>14362</td>\n",
       "      <td>64462</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>2013-08-23 22:57:58</td>\n",
       "      <td>RT @AJAMStream: BREAKING: San Diego Mayor Bob ...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>371043672814403584</td>\n",
       "      <td>950262462</td>\n",
       "      <td>theelsmom</td>\n",
       "      <td>2012-11-15 18:47:58</td>\n",
       "      <td>3198</td>\n",
       "      <td>2373</td>\n",
       "      <td>FL. GA. border</td>\n",
       "      <td>False</td>\n",
       "      <td>55+ wh. woman, third generation liberal Democr...</td>\n",
       "      <td>66</td>\n",
       "      <td>1921</td>\n",
       "      <td>14397</td>\n",
       "      <td>True</td>\n",
       "      <td>66</td>\n",
       "      <td>2013-08-23 22:57:59</td>\n",
       "      <td>RT @jennymedina: Filner is resigning but says ...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>371043670679515136</td>\n",
       "      <td>23448437</td>\n",
       "      <td>jruuiz</td>\n",
       "      <td>2009-03-09 15:34:48</td>\n",
       "      <td>144</td>\n",
       "      <td>171</td>\n",
       "      <td>La Mesa</td>\n",
       "      <td>False</td>\n",
       "      <td>filth. SanDiego. Usually tweeting about sports...</td>\n",
       "      <td>9</td>\n",
       "      <td>1669</td>\n",
       "      <td>22010</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>2013-08-23 22:57:59</td>\n",
       "      <td>RT @CNN: San Diego mayor resigns after sexual ...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>371043670469787651</td>\n",
       "      <td>15817399</td>\n",
       "      <td>CorporaCallosa</td>\n",
       "      <td>2008-08-12 02:19:20</td>\n",
       "      <td>748</td>\n",
       "      <td>4867</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>False</td>\n",
       "      <td>PoliSci/band/computer/Japan/disaster nerd and ...</td>\n",
       "      <td>55</td>\n",
       "      <td>72529</td>\n",
       "      <td>41305</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-08-23 22:57:59</td>\n",
       "      <td>RT @BreakingNews: San Diego Mayor resigns over...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>371043684328144896</td>\n",
       "      <td>150314589</td>\n",
       "      <td>TRob7125</td>\n",
       "      <td>2010-05-31 16:35:43</td>\n",
       "      <td>688</td>\n",
       "      <td>638</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>False</td>\n",
       "      <td>USW Local 9-392 Labor-Mgmt Consultant. Hypocri...</td>\n",
       "      <td>23</td>\n",
       "      <td>22932</td>\n",
       "      <td>21469</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>2013-08-23 22:58:02</td>\n",
       "      <td>RT @CNN: San Diego mayor resigns after sexual ...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>371043702233255936</td>\n",
       "      <td>1044241</td>\n",
       "      <td>brooklynmarie</td>\n",
       "      <td>2007-03-12 21:28:12</td>\n",
       "      <td>37262</td>\n",
       "      <td>15040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Chaotic good lovable rogue. Retweets mean I'm ...</td>\n",
       "      <td>696</td>\n",
       "      <td>298100</td>\n",
       "      <td>130972</td>\n",
       "      <td>False</td>\n",
       "      <td>696</td>\n",
       "      <td>2013-08-23 22:58:06</td>\n",
       "      <td>RT @BBCBreaking: San Diego mayor Bob Filner an...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>371043702208073729</td>\n",
       "      <td>413389727</td>\n",
       "      <td>twEEKdeezy</td>\n",
       "      <td>2011-11-15 20:43:17</td>\n",
       "      <td>418</td>\n",
       "      <td>469</td>\n",
       "      <td>Tiamat</td>\n",
       "      <td>False</td>\n",
       "      <td>‚ú®Forever evolving ‚ú®Lightwerkerz‚ú®</td>\n",
       "      <td>5</td>\n",
       "      <td>944</td>\n",
       "      <td>14791</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-08-23 22:58:06</td>\n",
       "      <td>RT @BBCBreaking: San Diego Mayor Bob Filner qu...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>371043726455762944</td>\n",
       "      <td>417549927</td>\n",
       "      <td>DaylightAtheism</td>\n",
       "      <td>2011-11-21 02:49:35</td>\n",
       "      <td>3939</td>\n",
       "      <td>179</td>\n",
       "      <td>New York City</td>\n",
       "      <td>False</td>\n",
       "      <td>Atheist author and speaker, writer for @patheo...</td>\n",
       "      <td>157</td>\n",
       "      <td>2387</td>\n",
       "      <td>16485</td>\n",
       "      <td>False</td>\n",
       "      <td>157</td>\n",
       "      <td>2013-08-23 22:58:12</td>\n",
       "      <td>This sounds familiar. RT @LANow: #Filner says ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>371043738908631040</td>\n",
       "      <td>17724673</td>\n",
       "      <td>amanda384</td>\n",
       "      <td>2008-11-29 01:01:50</td>\n",
       "      <td>1405</td>\n",
       "      <td>3571</td>\n",
       "      <td>Fairfax, VA</td>\n",
       "      <td>False</td>\n",
       "      <td>Vice Chairman, @FairfaxGOP, #TrumpTrain, #Supp...</td>\n",
       "      <td>45</td>\n",
       "      <td>10212</td>\n",
       "      <td>8579</td>\n",
       "      <td>False</td>\n",
       "      <td>45</td>\n",
       "      <td>2013-08-23 22:58:15</td>\n",
       "      <td>RT @nbcwashington: #BREAKING: San Diego Mayor ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>371043738253934592</td>\n",
       "      <td>48017315</td>\n",
       "      <td>sammyslifeindc</td>\n",
       "      <td>2009-06-17 16:29:06</td>\n",
       "      <td>311</td>\n",
       "      <td>933</td>\n",
       "      <td>Arlington VA</td>\n",
       "      <td>False</td>\n",
       "      <td>Lover of movies, TV, theater, art, food, trave...</td>\n",
       "      <td>19</td>\n",
       "      <td>8512</td>\n",
       "      <td>5129</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>2013-08-23 22:58:15</td>\n",
       "      <td>RT @nbcwashington: #BREAKING: San Diego Mayor ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>371043737016598528</td>\n",
       "      <td>135702892</td>\n",
       "      <td>GlowingRedSign</td>\n",
       "      <td>2010-04-22 01:52:03</td>\n",
       "      <td>39</td>\n",
       "      <td>235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>He/Him. Expect Left politics and venting.</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24119</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-23 22:58:15</td>\n",
       "      <td>Strange that people would applaud a mayor forc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>371044267008856065</td>\n",
       "      <td>22109505</td>\n",
       "      <td>KristinKayNews</td>\n",
       "      <td>2009-02-27 04:57:47</td>\n",
       "      <td>1796</td>\n",
       "      <td>2354</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>True</td>\n",
       "      <td>Assistant News Director for @WLWT, and new mom...</td>\n",
       "      <td>60</td>\n",
       "      <td>4138</td>\n",
       "      <td>6101</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>2013-08-23 23:00:21</td>\n",
       "      <td>Mayor #Filner done speaking, city attorney #Go...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>371044286608838657</td>\n",
       "      <td>170913342</td>\n",
       "      <td>HockeyTarheel</td>\n",
       "      <td>2010-07-26 02:54:01</td>\n",
       "      <td>506</td>\n",
       "      <td>2613</td>\n",
       "      <td>Northern Virginia/DC</td>\n",
       "      <td>False</td>\n",
       "      <td>Puck Daddy. Lutheran. Movie Buff</td>\n",
       "      <td>53</td>\n",
       "      <td>911</td>\n",
       "      <td>70008</td>\n",
       "      <td>True</td>\n",
       "      <td>53</td>\n",
       "      <td>2013-08-23 23:00:26</td>\n",
       "      <td>That Mayor Filner resignation press conference...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>371044340023316480</td>\n",
       "      <td>25640937</td>\n",
       "      <td>isabellenews</td>\n",
       "      <td>2009-03-21 04:44:33</td>\n",
       "      <td>3208</td>\n",
       "      <td>979</td>\n",
       "      <td>FRESNO, CALIFORNIA</td>\n",
       "      <td>True</td>\n",
       "      <td>News Anchor/Reporter for @ABC30. Daughter, wif...</td>\n",
       "      <td>59</td>\n",
       "      <td>2705</td>\n",
       "      <td>5861</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>2013-08-23 23:00:38</td>\n",
       "      <td>Mayor Bob Filner says if he was given \"due pro...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>371044343747862530</td>\n",
       "      <td>25556599</td>\n",
       "      <td>RyanPurdySD</td>\n",
       "      <td>2009-03-20 19:10:40</td>\n",
       "      <td>725</td>\n",
       "      <td>1096</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>False</td>\n",
       "      <td>Irish-#Catholic, die-hard UCLA Bruin fan and r...</td>\n",
       "      <td>33</td>\n",
       "      <td>1873</td>\n",
       "      <td>12520</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "      <td>2013-08-23 23:00:39</td>\n",
       "      <td>MT @MeanestBossEver: So did #Filner not go to ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>371044347405283328</td>\n",
       "      <td>15652540</td>\n",
       "      <td>KTVU</td>\n",
       "      <td>2008-07-29 22:29:44</td>\n",
       "      <td>455466</td>\n",
       "      <td>1285</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>True</td>\n",
       "      <td>Complete Bay Area News Coverage. Thanks for fo...</td>\n",
       "      <td>3418</td>\n",
       "      <td>1418</td>\n",
       "      <td>216555</td>\n",
       "      <td>False</td>\n",
       "      <td>3418</td>\n",
       "      <td>2013-08-23 23:00:40</td>\n",
       "      <td>AP: #SanDiego Mayor Bob Filner apologizes to a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>371044357698093056</td>\n",
       "      <td>1601236118</td>\n",
       "      <td>sooldman</td>\n",
       "      <td>2013-07-17 15:40:22</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>Corvallis, OR</td>\n",
       "      <td>False</td>\n",
       "      <td>64 yrs old...retired social programs manager.....</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>156</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-23 23:00:43</td>\n",
       "      <td>How dare Filner quote Sen Ted Kennedy...Ex-May...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>371044384529076224</td>\n",
       "      <td>1398594966</td>\n",
       "      <td>CharlieKadado</td>\n",
       "      <td>2013-05-03 01:56:58</td>\n",
       "      <td>797</td>\n",
       "      <td>700</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>False</td>\n",
       "      <td>Online editor at @lebexaminer.</td>\n",
       "      <td>28</td>\n",
       "      <td>1053</td>\n",
       "      <td>2857</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>2013-08-23 23:00:49</td>\n",
       "      <td>#BREAKING: #SanDiego mayor Bob #Filner resigns...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>371044385627967489</td>\n",
       "      <td>1507370221</td>\n",
       "      <td>riANALItimelow</td>\n",
       "      <td>2013-06-11 23:07:51</td>\n",
       "      <td>51</td>\n",
       "      <td>148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>UNFOLLOW THIS ACCOUNT AND FOLLOW @Statechampsny</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "      <td>7792</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-23 23:00:49</td>\n",
       "      <td>‚Äú@wtfjagk: ‚Äú@cosmicbarakat: hey tissue can i b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>371044405014048768</td>\n",
       "      <td>72502169</td>\n",
       "      <td>JohnnyAi</td>\n",
       "      <td>2009-09-08 08:01:25</td>\n",
       "      <td>2339</td>\n",
       "      <td>375</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>False</td>\n",
       "      <td>Columnist, Democratic Commentator | CA üõ´ DC | ...</td>\n",
       "      <td>62</td>\n",
       "      <td>38242</td>\n",
       "      <td>58717</td>\n",
       "      <td>False</td>\n",
       "      <td>62</td>\n",
       "      <td>2013-08-23 23:00:54</td>\n",
       "      <td>It wsnt the allgtns tht embrrssd me as an SD r...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>371044409082535936</td>\n",
       "      <td>571269666</td>\n",
       "      <td>Ijok1998</td>\n",
       "      <td>2012-05-04 21:58:28</td>\n",
       "      <td>731</td>\n",
       "      <td>625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Liberal progressive cat who believes in scienc...</td>\n",
       "      <td>41</td>\n",
       "      <td>11408</td>\n",
       "      <td>32566</td>\n",
       "      <td>False</td>\n",
       "      <td>41</td>\n",
       "      <td>2013-08-23 23:00:55</td>\n",
       "      <td>#tcot #GOP Mayor #Filner : \"Lord knows I'm not...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>371044459321892865</td>\n",
       "      <td>22109505</td>\n",
       "      <td>KristinKayNews</td>\n",
       "      <td>2009-02-27 04:57:47</td>\n",
       "      <td>1796</td>\n",
       "      <td>2354</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>True</td>\n",
       "      <td>Assistant News Director for @WLWT, and new mom...</td>\n",
       "      <td>60</td>\n",
       "      <td>4138</td>\n",
       "      <td>6101</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>2013-08-23 23:01:07</td>\n",
       "      <td>Mayor #Filner will remain in office until Augi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>371044458684362752</td>\n",
       "      <td>50068051</td>\n",
       "      <td>kellimckay</td>\n",
       "      <td>2009-06-23 19:07:11</td>\n",
       "      <td>232</td>\n",
       "      <td>285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>DJ extraordinaire weekdays 2p - 6p on Rewind 9...</td>\n",
       "      <td>12</td>\n",
       "      <td>71</td>\n",
       "      <td>5328</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-08-23 23:01:07</td>\n",
       "      <td>RT @NBCLA: #BREAKING: SD City Council accepts ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>371044463444901888</td>\n",
       "      <td>21902927</td>\n",
       "      <td>letsgoviralnow</td>\n",
       "      <td>2009-02-25 19:04:17</td>\n",
       "      <td>4795</td>\n",
       "      <td>3516</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>False</td>\n",
       "      <td>LGVN Combines marketing and social media manag...</td>\n",
       "      <td>26</td>\n",
       "      <td>199</td>\n",
       "      <td>99962</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>2013-08-23 23:01:08</td>\n",
       "      <td>A sexual harassment and discrimination lawsuit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>371044473855148033</td>\n",
       "      <td>9616062</td>\n",
       "      <td>10News</td>\n",
       "      <td>2007-10-23 06:12:28</td>\n",
       "      <td>170401</td>\n",
       "      <td>15656</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>True</td>\n",
       "      <td>Get all the major news that matters to you fro...</td>\n",
       "      <td>1892</td>\n",
       "      <td>4493</td>\n",
       "      <td>162332</td>\n",
       "      <td>False</td>\n",
       "      <td>1892</td>\n",
       "      <td>2013-08-23 23:01:10</td>\n",
       "      <td>RT @10NewsChen: Mayor #Filner: this was the to...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>371044519623417856</td>\n",
       "      <td>352387148</td>\n",
       "      <td>EAA84</td>\n",
       "      <td>2011-08-10 15:07:36</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>1668</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-23 23:01:21</td>\n",
       "      <td>Filner is out as SD mayor, Bales is in prison ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>371044536685850625</td>\n",
       "      <td>18783905</td>\n",
       "      <td>scottshafer</td>\n",
       "      <td>2009-01-08 23:16:23</td>\n",
       "      <td>6275</td>\n",
       "      <td>994</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>False</td>\n",
       "      <td>KQED Politics Editor. Co-host of Political Bre...</td>\n",
       "      <td>257</td>\n",
       "      <td>872</td>\n",
       "      <td>5200</td>\n",
       "      <td>True</td>\n",
       "      <td>257</td>\n",
       "      <td>2013-08-23 23:01:25</td>\n",
       "      <td>SD Mayor #BobFilner resigns. Denies sexual har...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>371044541064691713</td>\n",
       "      <td>754109270</td>\n",
       "      <td>PaulFeldman3350</td>\n",
       "      <td>2012-08-13 00:59:54</td>\n",
       "      <td>6729</td>\n",
       "      <td>3698</td>\n",
       "      <td>Napa, CA</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>9130</td>\n",
       "      <td>48868</td>\n",
       "      <td>True</td>\n",
       "      <td>62</td>\n",
       "      <td>2013-08-23 23:01:26</td>\n",
       "      <td>RT @RichardGrenell: Free hugs for the last wee...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>371044543283466242</td>\n",
       "      <td>32005408</td>\n",
       "      <td>jefferrrson</td>\n",
       "      <td>2009-04-16 17:25:44</td>\n",
       "      <td>1142</td>\n",
       "      <td>1263</td>\n",
       "      <td>San Diego's Finest</td>\n",
       "      <td>False</td>\n",
       "      <td>#1xTV #teamhoopery</td>\n",
       "      <td>13</td>\n",
       "      <td>22381</td>\n",
       "      <td>54759</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>2013-08-23 23:01:27</td>\n",
       "      <td>RT @10NewsChen: Mayor #Filner: this was the to...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>371044554499035136</td>\n",
       "      <td>42291452</td>\n",
       "      <td>MattCorrales</td>\n",
       "      <td>2009-05-24 22:08:25</td>\n",
       "      <td>716</td>\n",
       "      <td>2226</td>\n",
       "      <td>San Diego, CA, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>#ReturningCitizen #Queer #Chicano #Feminist #P...</td>\n",
       "      <td>21</td>\n",
       "      <td>576</td>\n",
       "      <td>6136</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>2013-08-23 23:01:30</td>\n",
       "      <td>To soon to be former Mayor #Filner: http://t.c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [{u'id': 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>371044584064692224</td>\n",
       "      <td>1051623260</td>\n",
       "      <td>danochoajr92</td>\n",
       "      <td>2013-01-01 02:12:30</td>\n",
       "      <td>511</td>\n",
       "      <td>1933</td>\n",
       "      <td>El Centro CA USA</td>\n",
       "      <td>False</td>\n",
       "      <td>public speaker, Veterans Rep, political consul...</td>\n",
       "      <td>15</td>\n",
       "      <td>254</td>\n",
       "      <td>50020</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>2013-08-23 23:01:37</td>\n",
       "      <td>Mayor Bob Filner Said Hes not Perfect, But Tak...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>371044600393502722</td>\n",
       "      <td>9616062</td>\n",
       "      <td>10News</td>\n",
       "      <td>2007-10-23 06:12:28</td>\n",
       "      <td>170401</td>\n",
       "      <td>15656</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>True</td>\n",
       "      <td>Get all the major news that matters to you fro...</td>\n",
       "      <td>1892</td>\n",
       "      <td>4493</td>\n",
       "      <td>162332</td>\n",
       "      <td>False</td>\n",
       "      <td>1892</td>\n",
       "      <td>2013-08-23 23:01:41</td>\n",
       "      <td>Settlement does not involve resolution of any ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>371044654491652096</td>\n",
       "      <td>214907115</td>\n",
       "      <td>pcessac</td>\n",
       "      <td>2010-11-12 14:38:04</td>\n",
       "      <td>147</td>\n",
       "      <td>236</td>\n",
       "      <td>Pearland, Texas</td>\n",
       "      <td>False</td>\n",
       "      <td>Engineering Department. Platting and Right of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>237</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-23 23:01:53</td>\n",
       "      <td>Really Mr. Filner, cause you're not mayor anym...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>371044654961000448</td>\n",
       "      <td>853088881</td>\n",
       "      <td>itzmide</td>\n",
       "      <td>2012-09-29 15:28:28</td>\n",
       "      <td>594</td>\n",
       "      <td>319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>#God1st#onlygurlfriendlysimplicityisallaboutme...</td>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>481333</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "      <td>2013-08-23 23:01:54</td>\n",
       "      <td>Bob Filner agrees to resign: Facing sexual har...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>371044662473023489</td>\n",
       "      <td>1617328646</td>\n",
       "      <td>CentralNewsPage</td>\n",
       "      <td>2013-07-24 09:26:12</td>\n",
       "      <td>195</td>\n",
       "      <td>208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NEWS, CNN, NBC, ABC, CBS, GOOGLE NEWS, REUTERS...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>77855</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-08-23 23:01:55</td>\n",
       "      <td>Bob Filner agrees to resign: Facing sexual har...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>371044658874294272</td>\n",
       "      <td>223554119</td>\n",
       "      <td>Olusola_lion000</td>\n",
       "      <td>2010-12-06 18:21:32</td>\n",
       "      <td>460</td>\n",
       "      <td>969</td>\n",
       "      <td>In Your Head</td>\n",
       "      <td>False</td>\n",
       "      <td>MY LIFE OR YOURS ? ü¶çü¶çü¶ç#420fam</td>\n",
       "      <td>3</td>\n",
       "      <td>417</td>\n",
       "      <td>51531</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-08-23 23:01:55</td>\n",
       "      <td>Bob Filner agrees to resign: Facing sexual har...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>371044665950101505</td>\n",
       "      <td>1595101634</td>\n",
       "      <td>BrockLeighton</td>\n",
       "      <td>2013-07-15 05:54:22</td>\n",
       "      <td>43</td>\n",
       "      <td>275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>33328</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>2013-08-23 23:01:56</td>\n",
       "      <td>Bob Filner agrees to resign: Facing sexual har...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>371044670966489089</td>\n",
       "      <td>1595121085</td>\n",
       "      <td>GaryDaviz5</td>\n",
       "      <td>2013-07-15 05:54:45</td>\n",
       "      <td>45</td>\n",
       "      <td>254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33346</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>2013-08-23 23:01:57</td>\n",
       "      <td>Bob Filner agrees to resign: Facing sexual har...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>371044667539746817</td>\n",
       "      <td>1595101568</td>\n",
       "      <td>KeiraLeila</td>\n",
       "      <td>2013-07-15 05:54:27</td>\n",
       "      <td>47</td>\n",
       "      <td>279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>33313</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>2013-08-23 23:01:57</td>\n",
       "      <td>Bob Filner agrees to resign: Facing sexual har...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>371044674405822464</td>\n",
       "      <td>1595122177</td>\n",
       "      <td>AliceResse</td>\n",
       "      <td>2013-07-15 05:55:42</td>\n",
       "      <td>47</td>\n",
       "      <td>275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>33334</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>2013-08-23 23:01:58</td>\n",
       "      <td>Bob Filner agrees to resign: Facing sexual har...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>371044672736489472</td>\n",
       "      <td>1595121901</td>\n",
       "      <td>SandraJost8</td>\n",
       "      <td>2013-07-15 05:55:16</td>\n",
       "      <td>43</td>\n",
       "      <td>265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>33338</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>2013-08-23 23:01:58</td>\n",
       "      <td>Bob Filner agrees to resign: Facing sexual har...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{u'symbols': [], u'user_mentions': [], u'hasht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    event_id            tweet_id     user_id      screen_name  \\\n",
       "0          1  371043472397987841    16436153  michaelcorcoran   \n",
       "1          1  371043478404222976    43337221    MrJaredBarnes   \n",
       "2          1  371043512642719744   343055758    wrigleylemons   \n",
       "3          1  371043526026752000   456094924    runbaileyrun_   \n",
       "4          1  371043523262312448   205143160       JamesVal70   \n",
       "5          1  371043530598150145    19266265      twocitylife   \n",
       "6          1  371043543373975552   489647114        popleibel   \n",
       "7          1  371043558095982595    37018152      james_laker   \n",
       "8          1  371043556225318912   305223472    LaurenSteussy   \n",
       "9          1  371043567520595968   250378882        eddiekimx   \n",
       "10         1  371043568896733184   581168201  PhilipAMonteiro   \n",
       "11         1  371043589054144513    22025982         RoshiniR   \n",
       "12         1  371043589930762240    23217897       dardar1126   \n",
       "13         1  371043625431339008     8010462    randyjohnston   \n",
       "14         1  371043634151718912   264307945  FixingNewsRjcts   \n",
       "15         1  371043637892632576    43023750        megcglass   \n",
       "16         1  371043640065286144    73800348          ryukan2   \n",
       "17         1  371043648768450560   106551925       Marco_NY23   \n",
       "18         1  371043665248284672   155329660       tony_manna   \n",
       "19         1  371043666212552704    15412641        TimmyShea   \n",
       "20         1  371043672814403584   950262462        theelsmom   \n",
       "21         1  371043670679515136    23448437           jruuiz   \n",
       "22         1  371043670469787651    15817399   CorporaCallosa   \n",
       "23         1  371043684328144896   150314589         TRob7125   \n",
       "24         1  371043702233255936     1044241    brooklynmarie   \n",
       "25         1  371043702208073729   413389727       twEEKdeezy   \n",
       "26         1  371043726455762944   417549927  DaylightAtheism   \n",
       "27         1  371043738908631040    17724673        amanda384   \n",
       "28         1  371043738253934592    48017315   sammyslifeindc   \n",
       "29         1  371043737016598528   135702892   GlowingRedSign   \n",
       "..       ...                 ...         ...              ...   \n",
       "70         1  371044267008856065    22109505   KristinKayNews   \n",
       "71         1  371044286608838657   170913342    HockeyTarheel   \n",
       "72         1  371044340023316480    25640937     isabellenews   \n",
       "73         1  371044343747862530    25556599      RyanPurdySD   \n",
       "74         1  371044347405283328    15652540             KTVU   \n",
       "75         1  371044357698093056  1601236118         sooldman   \n",
       "76         1  371044384529076224  1398594966    CharlieKadado   \n",
       "77         1  371044385627967489  1507370221   riANALItimelow   \n",
       "78         1  371044405014048768    72502169         JohnnyAi   \n",
       "79         1  371044409082535936   571269666         Ijok1998   \n",
       "80         1  371044459321892865    22109505   KristinKayNews   \n",
       "81         1  371044458684362752    50068051       kellimckay   \n",
       "82         1  371044463444901888    21902927   letsgoviralnow   \n",
       "83         1  371044473855148033     9616062           10News   \n",
       "84         1  371044519623417856   352387148            EAA84   \n",
       "85         1  371044536685850625    18783905      scottshafer   \n",
       "86         1  371044541064691713   754109270  PaulFeldman3350   \n",
       "87         1  371044543283466242    32005408      jefferrrson   \n",
       "88         1  371044554499035136    42291452     MattCorrales   \n",
       "89         1  371044584064692224  1051623260     danochoajr92   \n",
       "90         1  371044600393502722     9616062           10News   \n",
       "91         1  371044654491652096   214907115          pcessac   \n",
       "92         1  371044654961000448   853088881          itzmide   \n",
       "93         1  371044662473023489  1617328646  CentralNewsPage   \n",
       "94         1  371044658874294272   223554119  Olusola_lion000   \n",
       "95         1  371044665950101505  1595101634    BrockLeighton   \n",
       "96         1  371044670966489089  1595121085       GaryDaviz5   \n",
       "97         1  371044667539746817  1595101568       KeiraLeila   \n",
       "98         1  371044674405822464  1595122177       AliceResse   \n",
       "99         1  371044672736489472  1595121901      SandraJost8   \n",
       "\n",
       "           signup_time  followers_count  friends_count  \\\n",
       "0  2008-09-24 15:57:12             3787           2037   \n",
       "1  2009-05-29 14:17:51              456            335   \n",
       "2  2011-07-27 00:30:14               59            102   \n",
       "3  2012-01-05 21:32:38              616            557   \n",
       "4  2010-10-20 07:20:06             4980           5419   \n",
       "5  2009-01-21 00:10:00             1140           1129   \n",
       "6  2012-02-11 18:56:14             2697           2069   \n",
       "7  2009-05-01 19:23:26             5172           3948   \n",
       "8  2011-05-25 21:13:16             1885           2651   \n",
       "9  2011-02-11 00:01:49             1520           1398   \n",
       "10 2012-05-15 19:16:23              558            470   \n",
       "11 2009-02-26 16:11:28             4849           4148   \n",
       "12 2009-03-07 18:15:57              770            459   \n",
       "13 2007-08-07 03:13:08             1011            930   \n",
       "14 2011-03-11 17:51:18              101              0   \n",
       "15 2009-05-28 02:09:18              308            887   \n",
       "16 2009-09-13 03:13:53              422            383   \n",
       "17 2010-01-19 23:01:05             2737           4120   \n",
       "18 2010-06-13 20:56:20             5754           6925   \n",
       "19 2008-07-13 06:40:55             1517           1216   \n",
       "20 2012-11-15 18:47:58             3198           2373   \n",
       "21 2009-03-09 15:34:48              144            171   \n",
       "22 2008-08-12 02:19:20              748           4867   \n",
       "23 2010-05-31 16:35:43              688            638   \n",
       "24 2007-03-12 21:28:12            37262          15040   \n",
       "25 2011-11-15 20:43:17              418            469   \n",
       "26 2011-11-21 02:49:35             3939            179   \n",
       "27 2008-11-29 01:01:50             1405           3571   \n",
       "28 2009-06-17 16:29:06              311            933   \n",
       "29 2010-04-22 01:52:03               39            235   \n",
       "..                 ...              ...            ...   \n",
       "70 2009-02-27 04:57:47             1796           2354   \n",
       "71 2010-07-26 02:54:01              506           2613   \n",
       "72 2009-03-21 04:44:33             3208            979   \n",
       "73 2009-03-20 19:10:40              725           1096   \n",
       "74 2008-07-29 22:29:44           455466           1285   \n",
       "75 2013-07-17 15:40:22                2             12   \n",
       "76 2013-05-03 01:56:58              797            700   \n",
       "77 2013-06-11 23:07:51               51            148   \n",
       "78 2009-09-08 08:01:25             2339            375   \n",
       "79 2012-05-04 21:58:28              731            625   \n",
       "80 2009-02-27 04:57:47             1796           2354   \n",
       "81 2009-06-23 19:07:11              232            285   \n",
       "82 2009-02-25 19:04:17             4795           3516   \n",
       "83 2007-10-23 06:12:28           170401          15656   \n",
       "84 2011-08-10 15:07:36               49             39   \n",
       "85 2009-01-08 23:16:23             6275            994   \n",
       "86 2012-08-13 00:59:54             6729           3698   \n",
       "87 2009-04-16 17:25:44             1142           1263   \n",
       "88 2009-05-24 22:08:25              716           2226   \n",
       "89 2013-01-01 02:12:30              511           1933   \n",
       "90 2007-10-23 06:12:28           170401          15656   \n",
       "91 2010-11-12 14:38:04              147            236   \n",
       "92 2012-09-29 15:28:28              594            319   \n",
       "93 2013-07-24 09:26:12              195            208   \n",
       "94 2010-12-06 18:21:32              460            969   \n",
       "95 2013-07-15 05:54:22               43            275   \n",
       "96 2013-07-15 05:54:45               45            254   \n",
       "97 2013-07-15 05:54:27               47            279   \n",
       "98 2013-07-15 05:55:42               47            275   \n",
       "99 2013-07-15 05:55:16               43            265   \n",
       "\n",
       "                   location  verified  \\\n",
       "0              Mediocre, TX     False   \n",
       "1                 Worldwide     False   \n",
       "2            Here and there     False   \n",
       "3             WILMINGTON MA     False   \n",
       "4             San Diego, CA     False   \n",
       "5   San Diego / Palm Desert     False   \n",
       "6       Punta Arenas, Chile     False   \n",
       "7             San Diego, CA     False   \n",
       "8              New York, NY     False   \n",
       "9       Los Angeles, Calif.     False   \n",
       "10                      NaN     False   \n",
       "11           Global Citizen     False   \n",
       "12                    Texas     False   \n",
       "13                St. Louis     False   \n",
       "14                      NaN     False   \n",
       "15                      NaN     False   \n",
       "16                      NaN     False   \n",
       "17                      NaN     False   \n",
       "18              Florida-Man     False   \n",
       "19             New York, NY     False   \n",
       "20           FL. GA. border     False   \n",
       "21                  La Mesa     False   \n",
       "22            San Diego, CA     False   \n",
       "23                Miami, FL     False   \n",
       "24                      NaN      True   \n",
       "25                   Tiamat     False   \n",
       "26            New York City     False   \n",
       "27              Fairfax, VA     False   \n",
       "28             Arlington VA     False   \n",
       "29                      NaN     False   \n",
       "..                      ...       ...   \n",
       "70           Cincinnati, OH      True   \n",
       "71     Northern Virginia/DC     False   \n",
       "72       FRESNO, CALIFORNIA      True   \n",
       "73                San Diego     False   \n",
       "74              Oakland, CA      True   \n",
       "75            Corvallis, OR     False   \n",
       "76              Detroit, MI     False   \n",
       "77                      NaN     False   \n",
       "78           Washington, DC     False   \n",
       "79                      NaN     False   \n",
       "80           Cincinnati, OH      True   \n",
       "81                      NaN     False   \n",
       "82              Atlanta, GA     False   \n",
       "83            San Diego, CA      True   \n",
       "84                  Arizona     False   \n",
       "85            San Francisco     False   \n",
       "86                 Napa, CA     False   \n",
       "87       San Diego's Finest     False   \n",
       "88       San Diego, CA, USA     False   \n",
       "89        El Centro CA USA      False   \n",
       "90            San Diego, CA      True   \n",
       "91          Pearland, Texas     False   \n",
       "92                      NaN     False   \n",
       "93                      NaN     False   \n",
       "94             In Your Head     False   \n",
       "95                      NaN     False   \n",
       "96                      NaN     False   \n",
       "97                      NaN     False   \n",
       "98                      NaN     False   \n",
       "99                      NaN     False   \n",
       "\n",
       "                                     user_description  listed_count  \\\n",
       "0   Opinions on everything, but only an authority ...           135   \n",
       "1             Im here for a good time not a long time            16   \n",
       "2                       Attatchment leads to jealousy             0   \n",
       "3   ‚Ä¢ You are crazy, my child. You must go to Berl...             8   \n",
       "4   Christian, Father, Musician,Independent - #The...            98   \n",
       "5                                Curator / Journalist            71   \n",
       "6   Entre mis recuerdos audi√≥filos m√°s tempranos (...           199   \n",
       "7   No matter the opponents Game Man Listens Own O...           120   \n",
       "8   Features reporter/editor at the New York Post,...            75   \n",
       "9   Writing features for @WeAreMel. Seen/heard in ...            90   \n",
       "10  Law student. Civil Air Patrol officer. Trumpet...             5   \n",
       "11  Crisis Coach; @WCCORadio Host; Media Analyst; ...           221   \n",
       "12  Perpetual student of life*pro-equal rights for...           109   \n",
       "13   Views mine. RTs not endorsements. Yadda yadda...            25   \n",
       "14                   Messages rejected by @FixingNews             4   \n",
       "15             likes stuff. enjoys the san diego sun.            16   \n",
       "16                                                NaN            40   \n",
       "17  PR & Corp. Comms, Journalist & Storyteller | P...           656   \n",
       "18  I organize noise- #Conservatarian ChristianŸÜ &...            91   \n",
       "19  NY, by way of DC. ‚úàÔ∏è. Technology, infrastructu...            64   \n",
       "20  55+ wh. woman, third generation liberal Democr...            66   \n",
       "21  filth. SanDiego. Usually tweeting about sports...             9   \n",
       "22  PoliSci/band/computer/Japan/disaster nerd and ...            55   \n",
       "23  USW Local 9-392 Labor-Mgmt Consultant. Hypocri...            23   \n",
       "24  Chaotic good lovable rogue. Retweets mean I'm ...           696   \n",
       "25                   ‚ú®Forever evolving ‚ú®Lightwerkerz‚ú®             5   \n",
       "26  Atheist author and speaker, writer for @patheo...           157   \n",
       "27  Vice Chairman, @FairfaxGOP, #TrumpTrain, #Supp...            45   \n",
       "28  Lover of movies, TV, theater, art, food, trave...            19   \n",
       "29          He/Him. Expect Left politics and venting.             1   \n",
       "..                                                ...           ...   \n",
       "70  Assistant News Director for @WLWT, and new mom...            60   \n",
       "71                   Puck Daddy. Lutheran. Movie Buff            53   \n",
       "72  News Anchor/Reporter for @ABC30. Daughter, wif...            59   \n",
       "73  Irish-#Catholic, die-hard UCLA Bruin fan and r...            33   \n",
       "74  Complete Bay Area News Coverage. Thanks for fo...          3418   \n",
       "75  64 yrs old...retired social programs manager.....             0   \n",
       "76                     Online editor at @lebexaminer.            28   \n",
       "77    UNFOLLOW THIS ACCOUNT AND FOLLOW @Statechampsny             0   \n",
       "78  Columnist, Democratic Commentator | CA üõ´ DC | ...            62   \n",
       "79  Liberal progressive cat who believes in scienc...            41   \n",
       "80  Assistant News Director for @WLWT, and new mom...            60   \n",
       "81  DJ extraordinaire weekdays 2p - 6p on Rewind 9...            12   \n",
       "82  LGVN Combines marketing and social media manag...            26   \n",
       "83  Get all the major news that matters to you fro...          1892   \n",
       "84                                                NaN             0   \n",
       "85  KQED Politics Editor. Co-host of Political Bre...           257   \n",
       "86                                                NaN            62   \n",
       "87                                 #1xTV #teamhoopery            13   \n",
       "88  #ReturningCitizen #Queer #Chicano #Feminist #P...            21   \n",
       "89  public speaker, Veterans Rep, political consul...            15   \n",
       "90  Get all the major news that matters to you fro...          1892   \n",
       "91  Engineering Department. Platting and Right of ...             1   \n",
       "92  #God1st#onlygurlfriendlysimplicityisallaboutme...            71   \n",
       "93  NEWS, CNN, NBC, ABC, CBS, GOOGLE NEWS, REUTERS...             4   \n",
       "94                      MY LIFE OR YOURS ? ü¶çü¶çü¶ç#420fam             3   \n",
       "95                                                NaN            15   \n",
       "96                                                NaN            17   \n",
       "97                                                NaN            14   \n",
       "98                                                NaN            17   \n",
       "99                                                NaN            19   \n",
       "\n",
       "    favourites_count  statuses_count  default_profile  listed_count.1  \\\n",
       "0                344           10898            False             135   \n",
       "1               7648           55759            False              16   \n",
       "2               1487            2257             True               0   \n",
       "3              24907           16382             True               8   \n",
       "4               3722           23834            False              98   \n",
       "5              13585           18699            False              71   \n",
       "6             340931          371901            False             199   \n",
       "7                 22          274838            False             120   \n",
       "8               1753            4964            False              75   \n",
       "9               9514           18624            False              90   \n",
       "10            160746           10283             True               5   \n",
       "11              8761           20800            False             221   \n",
       "12             31173          272201             True             109   \n",
       "13              2767            6039            False              25   \n",
       "14                 0           20322             True               4   \n",
       "15             22803           96434            False              16   \n",
       "16              6530           60696             True              40   \n",
       "17              5599           82629            False             656   \n",
       "18              3489           16987            False              91   \n",
       "19             14362           64462            False              64   \n",
       "20              1921           14397             True              66   \n",
       "21              1669           22010            False               9   \n",
       "22             72529           41305            False              55   \n",
       "23             22932           21469            False              23   \n",
       "24            298100          130972            False             696   \n",
       "25               944           14791             True               5   \n",
       "26              2387           16485            False             157   \n",
       "27             10212            8579            False              45   \n",
       "28              8512            5129            False              19   \n",
       "29                 3           24119            False               1   \n",
       "..               ...             ...              ...             ...   \n",
       "70              4138            6101            False              60   \n",
       "71               911           70008             True              53   \n",
       "72              2705            5861            False              59   \n",
       "73              1873           12520             True              33   \n",
       "74              1418          216555            False            3418   \n",
       "75                 4             156             True               0   \n",
       "76              1053            2857            False              28   \n",
       "77               586            7792             True               0   \n",
       "78             38242           58717            False              62   \n",
       "79             11408           32566            False              41   \n",
       "80              4138            6101            False              60   \n",
       "81                71            5328            False              12   \n",
       "82               199           99962            False              26   \n",
       "83              4493          162332            False            1892   \n",
       "84               164            1668            False               0   \n",
       "85               872            5200             True             257   \n",
       "86              9130           48868             True              62   \n",
       "87             22381           54759            False              13   \n",
       "88               576            6136            False              21   \n",
       "89               254           50020             True              15   \n",
       "90              4493          162332            False            1892   \n",
       "91                29             237             True               1   \n",
       "92                15          481333             True              71   \n",
       "93                 0           77855             True               4   \n",
       "94               417           51531             True               3   \n",
       "95                 0           33328             True              15   \n",
       "96                 0           33346             True              17   \n",
       "97                 0           33313             True              14   \n",
       "98                 0           33334             True              17   \n",
       "99                 0           33338             True              19   \n",
       "\n",
       "      tweet_created_at                                 tweet_content_text  \\\n",
       "0  2013-08-23 22:57:12  San Diego mayor resigns amid sexual harassment...   \n",
       "1  2013-08-23 22:57:13  RT @CNN: San Diego mayor resigns after sexual ...   \n",
       "2  2013-08-23 22:57:21  Bye                       ‚Äú@CNN: San Diego may...   \n",
       "3  2013-08-23 22:57:24  RT @BostonGlobe: BREAKING: Embattled San Diego...   \n",
       "4  2013-08-23 22:57:24  V.CNN BREAKING San Diego City Council accepts ...   \n",
       "5  2013-08-23 22:57:26  RT @citybeatkelly: So, despite therapy, Filner...   \n",
       "6  2013-08-23 22:57:29  RT @WSJ: Breaking: San Diego Mayor Bob Filner ...   \n",
       "7  2013-08-23 22:57:32  RT @Yahoo: UPDATE: San Diego Mayor #BobFilner ...   \n",
       "8  2013-08-23 22:57:32  RT @citybeatkelly: So, despite therapy, Filner...   \n",
       "9  2013-08-23 22:57:34  RT @BostonGlobe: BREAKING: Embattled San Diego...   \n",
       "10 2013-08-23 22:57:35  RT @BBCBreaking: San Diego Mayor Bob Filner qu...   \n",
       "11 2013-08-23 22:57:39  RT @BostonGlobe: BREAKING: Embattled San Diego...   \n",
       "12 2013-08-23 22:57:40  RT @BostonGlobe: BREAKING: Embattled San Diego...   \n",
       "13 2013-08-23 22:57:48  RT @BostonGlobe: BREAKING: Embattled San Diego...   \n",
       "14 2013-08-23 22:57:50  RT @BBCBreaking: San Diego mayor Bob Filner an...   \n",
       "15 2013-08-23 22:57:51  RT @BostonGlobe: BREAKING: Embattled San Diego...   \n",
       "16 2013-08-23 22:57:52  Bob Filner Resigns: San Diego Mayor Agrees To ...   \n",
       "17 2013-08-23 22:57:54  RT @WSJ: Breaking: San Diego Mayor Bob Filner ...   \n",
       "18 2013-08-23 22:57:58  #WarOnWomen -Not only will the gov pay for all...   \n",
       "19 2013-08-23 22:57:58  RT @AJAMStream: BREAKING: San Diego Mayor Bob ...   \n",
       "20 2013-08-23 22:57:59  RT @jennymedina: Filner is resigning but says ...   \n",
       "21 2013-08-23 22:57:59  RT @CNN: San Diego mayor resigns after sexual ...   \n",
       "22 2013-08-23 22:57:59  RT @BreakingNews: San Diego Mayor resigns over...   \n",
       "23 2013-08-23 22:58:02  RT @CNN: San Diego mayor resigns after sexual ...   \n",
       "24 2013-08-23 22:58:06  RT @BBCBreaking: San Diego mayor Bob Filner an...   \n",
       "25 2013-08-23 22:58:06  RT @BBCBreaking: San Diego Mayor Bob Filner qu...   \n",
       "26 2013-08-23 22:58:12  This sounds familiar. RT @LANow: #Filner says ...   \n",
       "27 2013-08-23 22:58:15  RT @nbcwashington: #BREAKING: San Diego Mayor ...   \n",
       "28 2013-08-23 22:58:15  RT @nbcwashington: #BREAKING: San Diego Mayor ...   \n",
       "29 2013-08-23 22:58:15  Strange that people would applaud a mayor forc...   \n",
       "..                 ...                                                ...   \n",
       "70 2013-08-23 23:00:21  Mayor #Filner done speaking, city attorney #Go...   \n",
       "71 2013-08-23 23:00:26  That Mayor Filner resignation press conference...   \n",
       "72 2013-08-23 23:00:38  Mayor Bob Filner says if he was given \"due pro...   \n",
       "73 2013-08-23 23:00:39  MT @MeanestBossEver: So did #Filner not go to ...   \n",
       "74 2013-08-23 23:00:40  AP: #SanDiego Mayor Bob Filner apologizes to a...   \n",
       "75 2013-08-23 23:00:43  How dare Filner quote Sen Ted Kennedy...Ex-May...   \n",
       "76 2013-08-23 23:00:49  #BREAKING: #SanDiego mayor Bob #Filner resigns...   \n",
       "77 2013-08-23 23:00:49  ‚Äú@wtfjagk: ‚Äú@cosmicbarakat: hey tissue can i b...   \n",
       "78 2013-08-23 23:00:54  It wsnt the allgtns tht embrrssd me as an SD r...   \n",
       "79 2013-08-23 23:00:55  #tcot #GOP Mayor #Filner : \"Lord knows I'm not...   \n",
       "80 2013-08-23 23:01:07  Mayor #Filner will remain in office until Augi...   \n",
       "81 2013-08-23 23:01:07  RT @NBCLA: #BREAKING: SD City Council accepts ...   \n",
       "82 2013-08-23 23:01:08  A sexual harassment and discrimination lawsuit...   \n",
       "83 2013-08-23 23:01:10  RT @10NewsChen: Mayor #Filner: this was the to...   \n",
       "84 2013-08-23 23:01:21  Filner is out as SD mayor, Bales is in prison ...   \n",
       "85 2013-08-23 23:01:25  SD Mayor #BobFilner resigns. Denies sexual har...   \n",
       "86 2013-08-23 23:01:26  RT @RichardGrenell: Free hugs for the last wee...   \n",
       "87 2013-08-23 23:01:27  RT @10NewsChen: Mayor #Filner: this was the to...   \n",
       "88 2013-08-23 23:01:30  To soon to be former Mayor #Filner: http://t.c...   \n",
       "89 2013-08-23 23:01:37  Mayor Bob Filner Said Hes not Perfect, But Tak...   \n",
       "90 2013-08-23 23:01:41  Settlement does not involve resolution of any ...   \n",
       "91 2013-08-23 23:01:53  Really Mr. Filner, cause you're not mayor anym...   \n",
       "92 2013-08-23 23:01:54  Bob Filner agrees to resign: Facing sexual har...   \n",
       "93 2013-08-23 23:01:55  Bob Filner agrees to resign: Facing sexual har...   \n",
       "94 2013-08-23 23:01:55  Bob Filner agrees to resign: Facing sexual har...   \n",
       "95 2013-08-23 23:01:56  Bob Filner agrees to resign: Facing sexual har...   \n",
       "96 2013-08-23 23:01:57  Bob Filner agrees to resign: Facing sexual har...   \n",
       "97 2013-08-23 23:01:57  Bob Filner agrees to resign: Facing sexual har...   \n",
       "98 2013-08-23 23:01:58  Bob Filner agrees to resign: Facing sexual har...   \n",
       "99 2013-08-23 23:01:58  Bob Filner agrees to resign: Facing sexual har...   \n",
       "\n",
       "    retweet_count  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0             0.0                        NaN                  NaN   \n",
       "1           157.0                        NaN                  NaN   \n",
       "2             0.0               3.710414e+17             759251.0   \n",
       "3            14.0                        NaN                  NaN   \n",
       "4             0.0                        NaN                  NaN   \n",
       "5             6.0                        NaN                  NaN   \n",
       "6            45.0                        NaN                  NaN   \n",
       "7             6.0                        NaN                  NaN   \n",
       "8             6.0                        NaN                  NaN   \n",
       "9            14.0                        NaN                  NaN   \n",
       "10           85.0                        NaN                  NaN   \n",
       "11           14.0                        NaN                  NaN   \n",
       "12           14.0                        NaN                  NaN   \n",
       "13           14.0                        NaN                  NaN   \n",
       "14          112.0                        NaN                  NaN   \n",
       "15           14.0                        NaN                  NaN   \n",
       "16            0.0                        NaN                  NaN   \n",
       "17           45.0                        NaN                  NaN   \n",
       "18            1.0                        NaN                  NaN   \n",
       "19           15.0                        NaN                  NaN   \n",
       "20           33.0                        NaN                  NaN   \n",
       "21          157.0                        NaN                  NaN   \n",
       "22            0.0                        NaN                  NaN   \n",
       "23          157.0                        NaN                  NaN   \n",
       "24          112.0                        NaN                  NaN   \n",
       "25           85.0                        NaN                  NaN   \n",
       "26            2.0                        NaN                  NaN   \n",
       "27            4.0                        NaN                  NaN   \n",
       "28            4.0                        NaN                  NaN   \n",
       "29            0.0                        NaN                  NaN   \n",
       "..            ...                        ...                  ...   \n",
       "70            0.0                        NaN                  NaN   \n",
       "71            0.0                        NaN                  NaN   \n",
       "72            0.0                        NaN                  NaN   \n",
       "73            0.0                        NaN                  NaN   \n",
       "74            1.0                        NaN                  NaN   \n",
       "75            0.0                        NaN                  NaN   \n",
       "76            0.0                        NaN                  NaN   \n",
       "77            0.0                        NaN                  NaN   \n",
       "78            0.0                        NaN                  NaN   \n",
       "79            0.0                        NaN                  NaN   \n",
       "80            0.0                        NaN                  NaN   \n",
       "81            7.0                        NaN                  NaN   \n",
       "82            0.0                        NaN                  NaN   \n",
       "83            2.0                        NaN                  NaN   \n",
       "84            0.0                        NaN                  NaN   \n",
       "85            0.0                        NaN                  NaN   \n",
       "86            9.0                        NaN                  NaN   \n",
       "87            2.0                        NaN                  NaN   \n",
       "88            0.0                        NaN                  NaN   \n",
       "89            0.0                        NaN                  NaN   \n",
       "90            1.0                        NaN                  NaN   \n",
       "91            0.0                        NaN                  NaN   \n",
       "92            0.0                        NaN                  NaN   \n",
       "93            0.0                        NaN                  NaN   \n",
       "94            0.0                        NaN                  NaN   \n",
       "95            0.0                        NaN                  NaN   \n",
       "96            0.0                        NaN                  NaN   \n",
       "97            0.0                        NaN                  NaN   \n",
       "98            0.0                        NaN                  NaN   \n",
       "99            0.0                        NaN                  NaN   \n",
       "\n",
       "    favorite_count                                         entities\\r  \n",
       "0              0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "1              0.0  {u'symbols': [], u'user_mentions': [{u'id': 75...  \n",
       "2              0.0  {u'symbols': [], u'user_mentions': [{u'id': 75...  \n",
       "3              0.0  {u'symbols': [], u'user_mentions': [{u'id': 95...  \n",
       "4              0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "5              0.0  {u'symbols': [], u'user_mentions': [{u'id': 60...  \n",
       "6              0.0  {u'symbols': [], u'user_mentions': [{u'id': 31...  \n",
       "7              0.0  {u'symbols': [], u'user_mentions': [{u'id': 19...  \n",
       "8              0.0  {u'symbols': [], u'user_mentions': [{u'id': 60...  \n",
       "9              0.0  {u'symbols': [], u'user_mentions': [{u'id': 95...  \n",
       "10             0.0  {u'symbols': [], u'user_mentions': [{u'id': 54...  \n",
       "11             0.0  {u'symbols': [], u'user_mentions': [{u'id': 95...  \n",
       "12             0.0  {u'symbols': [], u'user_mentions': [{u'id': 95...  \n",
       "13             0.0  {u'symbols': [], u'user_mentions': [{u'id': 95...  \n",
       "14             0.0  {u'symbols': [], u'user_mentions': [{u'id': 54...  \n",
       "15             0.0  {u'symbols': [], u'user_mentions': [{u'id': 95...  \n",
       "16             0.0  {u'symbols': [], u'user_mentions': [{u'id': 15...  \n",
       "17             0.0  {u'symbols': [], u'user_mentions': [{u'id': 31...  \n",
       "18             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "19             0.0  {u'symbols': [], u'user_mentions': [{u'id': 30...  \n",
       "20             0.0  {u'symbols': [], u'user_mentions': [{u'id': 23...  \n",
       "21             0.0  {u'symbols': [], u'user_mentions': [{u'id': 75...  \n",
       "22             0.0  {u'symbols': [], u'user_mentions': [{u'id': 60...  \n",
       "23             0.0  {u'symbols': [], u'user_mentions': [{u'id': 75...  \n",
       "24             0.0  {u'symbols': [], u'user_mentions': [{u'id': 54...  \n",
       "25             0.0  {u'symbols': [], u'user_mentions': [{u'id': 54...  \n",
       "26             0.0  {u'symbols': [], u'user_mentions': [{u'id': 17...  \n",
       "27             0.0  {u'symbols': [], u'user_mentions': [{u'id': 14...  \n",
       "28             0.0  {u'symbols': [], u'user_mentions': [{u'id': 14...  \n",
       "29             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "..             ...                                                ...  \n",
       "70             0.0  {u'symbols': [], u'user_mentions': [{u'id': 96...  \n",
       "71             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "72             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "73             0.0  {u'symbols': [], u'user_mentions': [{u'id': 11...  \n",
       "74             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "75             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "76             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "77             0.0  {u'symbols': [], u'user_mentions': [{u'id': 26...  \n",
       "78             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "79             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "80             0.0  {u'symbols': [], u'user_mentions': [{u'id': 96...  \n",
       "81             0.0  {u'symbols': [], u'user_mentions': [{u'id': 17...  \n",
       "82             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "83             0.0  {u'symbols': [], u'user_mentions': [{u'id': 46...  \n",
       "84             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "85             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "86             0.0  {u'symbols': [], u'user_mentions': [{u'id': 90...  \n",
       "87             0.0  {u'symbols': [], u'user_mentions': [{u'id': 46...  \n",
       "88             0.0  {u'symbols': [], u'user_mentions': [{u'id': 10...  \n",
       "89             1.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "90             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "91             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "92             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "93             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "94             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "95             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "96             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "97             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "98             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "99             0.0  {u'symbols': [], u'user_mentions': [], u'hasht...  \n",
       "\n",
       "[100 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(953360, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'michaelcorcoranMrJaredBarnes'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0][3] + data.iloc[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(data.iloc[1]['in_reply_to_status_id_str']) == 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(data.iloc[2]['in_reply_to_status_id_str'],str):\n",
    "    print \"hurray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tweets=0\n",
    "tot_tweets=0\n",
    "no_users=0\n",
    "no_users_abs=0\n",
    "no_reinvolve_users=0\n",
    "possible_reaches_tot=0\n",
    "retweet_tot=0\n",
    "reply_tot=0\n",
    "faviorite_tot=0\n",
    "word_count=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    try:\n",
    "        row['tweet_created_at'].date()\n",
    "        origin  = row['tweet_created_at']\n",
    "        break\n",
    "    except Exception ,e:\n",
    "        print e\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_set={None}\n",
    "c_id = 1\n",
    "steps=10\n",
    "step_c=0\n",
    "time_gap_min=1\n",
    "X=[]\n",
    "data_point = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-08-23 22:57:12\n",
      "2013-08-23 22:58:12\n"
     ]
    }
   ],
   "source": [
    "print origin\n",
    "origin=origin + timedelta(minutes=time_gap_min)\n",
    "print origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[26, 26, 26, 0, 26, 82797, 1106.0, 25, 1058238, 500]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[42, 16, 16, 1, 15, 135707, 18.0, 16, 318787, 229]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[63, 21, 21, 0, 21, 124457, 59.0, 20, 232154, 343]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[81, 18, 18, 2, 16, 649255, 10.0, 18, 115956, 281]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[103, 22, 22, 2, 20, 17828, 24.0, 22, 49970, 408]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[122, 19, 19, 1, 18, 103296, 35.0, 17, 685759, 302]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[136, 14, 14, 1, 13, 101078, 63.0, 13, 255468, 250]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[152, 16, 16, 3, 13, 445979, 51.0, 16, 306797, 271]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[167, 15, 15, 1, 14, 106361, 40.0, 14, 450632, 281]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[174, 7, 7, 1, 6, 28409, 57.0, 7, 29227, 128]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "perfect-new event1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[10, 20, 20, 1, 19, 64513, 49.0, 17, 144031, 312]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[20, 10, 10, 0, 10, 529231, 42.0, 10, 44676, 180]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[28, 8, 8, 0, 8, 192159, 2.0, 8, 28117, 169]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[32, 4, 4, 1, 3, 206, 4.0, 3, 11576, 64]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[36, 4, 4, 0, 4, 433536, 7.0, 4, 19566, 72]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[45, 9, 9, 1, 8, 2865549, 20.0, 9, 57991, 153]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[49, 4, 4, 0, 4, 28536, 16.0, 4, 33691, 63]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[62, 13, 13, 1, 12, 398437, 69.0, 13, 198707, 204]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[69, 7, 7, 0, 7, 31837, 26.0, 7, 206059, 129]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[76, 7, 7, 1, 6, 70256, 29.0, 7, 29189, 121]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "perfect-new event1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[10, 19, 19, 1, 18, 239479, 46.0, 16, 191967, 310]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[19, 9, 9, 0, 9, 206147, 7.0, 7, 47103, 155]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[27, 8, 8, 1, 7, 39642, 8.0, 8, 82467, 133]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[34, 7, 7, 2, 5, 6114, 37.0, 7, 34367, 132]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[41, 7, 7, 1, 6, 43640, 8.0, 6, 39404, 113]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[60, 19, 19, 2, 17, 28217, 45.0, 19, 136311, 333]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[86, 26, 26, 1, 25, 53707, 31.0, 26, 130808, 473]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[95, 9, 9, 0, 9, 63740, 2.0, 9, 13692, 154]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[104, 9, 9, 1, 8, 13154, 41.0, 9, 158205, 174]\n",
      "1\n",
      "1\n",
      "[105, 1, 1, 0, 1, 5849, 8.0, 1, 117, 19]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "perfect-new event1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "[2, 13, 13, 5, 8, 43840, 31.0, 12, 24084, 225]\n",
      "1\n",
      "1\n",
      "[3, 1, 1, 0, 1, 3417, 0.0, 1, 9805, 16]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[10, 7, 7, 1, 6, 3446, 52.0, 7, 32542, 120]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[14, 4, 4, 0, 4, 18683, 1.0, 4, 66085, 74]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[18, 4, 4, 0, 4, 22802, 11.0, 4, 55553, 74]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[24, 6, 6, 0, 6, 8486, 13.0, 5, 47564, 115]\n",
      "1\n",
      "1\n",
      "1\n",
      "[26, 2, 2, 0, 2, 2675, 8.0, 2, 45903, 31]\n",
      "1\n",
      "1\n",
      "1\n",
      "[28, 2, 2, 0, 2, 138179, 0.0, 2, 13012, 43]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[34, 6, 6, 0, 6, 12854, 7.0, 5, 14790, 107]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[37, 3, 3, 0, 3, 5679, 36.0, 3, 22708, 71]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "perfect-new event1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[7, 13, 13, 0, 13, 199722, 21.0, 13, 100600, 251]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[13, 6, 6, 0, 6, 42504, 5.0, 4, 240379, 130]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[23, 10, 10, 2, 8, 201310, 21.0, 8, 484167, 175]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[26, 3, 3, 0, 3, 5919, 2.0, 2, 16051, 66]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[31, 5, 5, 0, 5, 34062, 12.0, 5, 67935, 103]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[35, 4, 4, 1, 3, 50067, 3.0, 3, 287697, 86]\n",
      "1\n",
      "1\n",
      "[36, 1, 1, 0, 1, 629, 1.0, 1, 33, 18]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[39, 3, 3, 0, 3, 10170, 2.0, 3, 22984, 55]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[46, 7, 7, 1, 6, 8163, 35.0, 7, 139667, 109]\n",
      "1\n",
      "1\n",
      "[47, 1, 1, 1, 0, 0, 0.0, 1, 8, 20]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "perfect-new event1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[3, 9, 9, 0, 9, 110665, 52.0, 9, 112942, 137]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[7, 4, 4, 1, 3, 8914, 5.0, 4, 69570, 77]\n",
      "1\n",
      "[7, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[10, 3, 3, 0, 3, 2202, 2.0, 3, 134007, 56]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[15, 5, 5, 0, 5, 27950, 3.0, 3, 28131, 67]\n",
      "1\n",
      "1\n",
      "[16, 1, 1, 0, 1, 553, 22.0, 1, 7999, 21]\n",
      "1\n",
      "[16, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[23, 7, 7, 0, 7, 182685, 125.0, 6, 87081, 148]\n",
      "1\n",
      "1\n",
      "1\n",
      "[25, 2, 2, 0, 2, 2899, 9.0, 2, 2521, 40]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[28, 3, 3, 0, 3, 239891, 0.0, 3, 9318, 47]\n",
      "1\n",
      "1\n",
      "perfect-new event1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "[2, 3, 3, 0, 3, 368222, 1.0, 3, 20501, 46]\n",
      "1\n",
      "1\n",
      "[3, 1, 1, 0, 1, 1967, 0.0, 1, 1095, 16]\n",
      "1\n",
      "1\n",
      "[4, 1, 1, 0, 1, 148872, 18.0, 1, 9852, 21]\n",
      "1\n",
      "1\n",
      "1\n",
      "[6, 2, 2, 0, 2, 53094, 21.0, 2, 5432, 30]\n",
      "1\n",
      "1\n",
      "[7, 1, 1, 0, 1, 3211, 3.0, 1, 8714, 10]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[10, 3, 3, 0, 3, 9519, 36.0, 3, 1331665, 60]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[15, 5, 5, 0, 5, 4500, 5.0, 5, 45381, 107]\n",
      "1\n",
      "1\n",
      "1\n",
      "[17, 2, 2, 0, 2, 1294, 0.0, 2, 28680, 39]\n",
      "1\n",
      "[17, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "1\n",
      "[18, 1, 1, 0, 1, 13, 0.0, 1, 0, 8]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "perfect-new event1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[3, 6, 6, 0, 6, 43459, 28.0, 6, 71674, 127]\n",
      "1\n",
      "[3, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "[3, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "1\n",
      "[4, 1, 1, 0, 1, 6127, 0.0, 1, 0, 16]\n",
      "1\n",
      "1\n",
      "[5, 1, 1, 0, 1, 4067, 0.0, 1, 8621, 30]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[8, 3, 3, 0, 3, 17919, 10.0, 3, 47290, 38]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[11, 3, 3, 0, 3, 107504, 120.0, 3, 30568, 52]\n",
      "1\n",
      "1\n",
      "[12, 1, 1, 0, 1, 7429, 7.0, 1, 2720, 21]\n",
      "1\n",
      "1\n",
      "[13, 1, 1, 0, 1, 187823, 5.0, 1, 3712, 12]\n",
      "1\n",
      "[13, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "perfect-new event1\n",
      "2\n",
      "1\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[5, 5, 5, 0, 5, 4013, 142.0, 5, 36052, 92]\n",
      "1\n",
      "1\n",
      "[6, 1, 1, 0, 1, 126, 0.0, 1, 73, 22]\n",
      "1\n",
      "1\n",
      "[7, 1, 1, 0, 1, 30, 0.0, 1, 120, 10]\n",
      "1\n",
      "1\n",
      "[8, 1, 1, 0, 1, 132, 0.0, 1, 18, 21]\n",
      "1\n",
      "1\n",
      "[9, 1, 1, 0, 1, 26135, 0.0, 1, 882, 10]\n",
      "1\n",
      "1\n",
      "perfect-new event1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "[2, 3, 3, 0, 3, 29990, 3.0, 3, 18237, 43]\n",
      "1\n",
      "1\n",
      "[3, 1, 1, 0, 1, 103, 0.0, 0, 525, 16]\n",
      "1\n",
      "1\n",
      "1\n",
      "[5, 2, 2, 0, 2, 4500, 4.0, 2, 96352, 42]\n",
      "1\n",
      "1\n",
      "[6, 1, 1, 0, 1, 192, 0.0, 1, 1696, 10]\n",
      "1\n",
      "[6, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "[6, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[9, 3, 3, 0, 3, 2655, 0.0, 3, 1349, 53]\n",
      "1\n",
      "[9, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "[9, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "1\n",
      "[10, 1, 1, 0, 1, 941, 1.0, 1, 932, 9]\n",
      "1\n",
      "perfect-new event1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-b9b446910b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0musr_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mindex2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0mrow2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet_created_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bawa/anaconda3/envs/FYP/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bawa/anaconda3/envs/FYP/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5323\u001b[0m         \"\"\"\n\u001b[1;32m   5324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5327\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bawa/anaconda3/envs/FYP/lib/python2.7/site-packages/pandas/core/internals/managers.pyc\u001b[0m in \u001b[0;36mas_array\u001b[0;34m(self, transpose, items)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtranspose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bawa/anaconda3/envs/FYP/lib/python2.7/site-packages/pandas/core/internals/managers.pyc\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bawa/anaconda3/envs/FYP/lib/python2.7/site-packages/pandas/core/internals/blocks.pyc\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2078\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, row in data.iterrows():\n",
    "    print c_id\n",
    "    if row['event_id']>c_id:\n",
    "#         print \"over drived\"\n",
    "        if (data_point.count>0):\n",
    "            c_id = row['event_id']\n",
    "            avg = np.mean(data_point,axis=0)\n",
    "            print \"overdrived-new event{} avg={}\".format(row['event_id'],avg)\n",
    "            if step_c<steps:\n",
    "                for x in range(step_c,steps):\n",
    "                    print \"avg\"\n",
    "                    data_point.append(avg)\n",
    "            step_c=0\n",
    "            X.append(data_point)\n",
    "            data_point=[]\n",
    "            tot_tweets=0\n",
    "            usr_set={None}\n",
    "\n",
    "            for index2, row2 in data.iloc[index:,:].iterrows():\n",
    "                try:\n",
    "                    row2['tweet_created_at'].date()\n",
    "                    origin  = row2['tweet_created_at']\n",
    "                    break\n",
    "                except Exception ,e:\n",
    "                    print e\n",
    "                    continue\n",
    "            origin=origin + timedelta(minutes=time_gap_min)\n",
    "        else:\n",
    "            step_c=0\n",
    "            data_point=[]\n",
    "            tot_tweets=0\n",
    "            usr_set={None}\n",
    "\n",
    "            for index2, row2 in data.iloc[index:,:].iterrows():\n",
    "                try:\n",
    "                    row2['tweet_created_at'].date()\n",
    "                    origin  = row2['tweet_created_at']\n",
    "                    c_id=row2['event_id']\n",
    "                    break\n",
    "                except Exception ,e:\n",
    "                    continue\n",
    "            origin=origin + timedelta(minutes=time_gap_min)\n",
    "        \n",
    "    \n",
    "    if row['event_id'] == c_id:\n",
    "        if row['tweet_created_at']<origin:\n",
    "            no_tweets=no_tweets+1\n",
    "            tot_tweets=tot_tweets+1\n",
    "            no_users= no_users+1\n",
    "            if row['user_id'] in usr_set:\n",
    "                no_reinvolve_users=no_reinvolve_users +1\n",
    "            else:\n",
    "                usr_set.add(row['user_id'])\n",
    "                no_users_abs= no_users_abs+1\n",
    "                possible_reaches_tot=possible_reaches_tot+row['followers_count']\n",
    "            retweet_tot=retweet_tot+row['retweet_count']\n",
    "            if str(row['in_reply_to_status_id_str']) == 'nan':\n",
    "                reply_tot=reply_tot+1\n",
    "            faviorite_tot = faviorite_tot+row['favourites_count']\n",
    "            word_count = word_count+len(row['tweet_content_text'].split())\n",
    "        else:\n",
    "            if step_c<steps:\n",
    "                step_c = step_c+1\n",
    "                ar = [tot_tweets,no_tweets, no_users,no_reinvolve_users,no_users_abs,possible_reaches_tot,retweet_tot,reply_tot,faviorite_tot,word_count]\n",
    "                data_point.append(ar)\n",
    "                print ar\n",
    "                origin=origin+timedelta(minutes=time_gap_min)\n",
    "                no_tweets=0\n",
    "                no_users=0\n",
    "                no_users_abs=0\n",
    "                no_reinvolve_users=0\n",
    "                possible_reaches_tot=0\n",
    "                retweet_tot=0\n",
    "                reply_tot=0\n",
    "                faviorite_tot=0\n",
    "                word_count=0\n",
    "            else:\n",
    "\n",
    "                print \"perfect-new event{}\".format(row['event_id'])\n",
    "                c_id=c_id+1\n",
    "                print c_id\n",
    "                step_c=0\n",
    "                X.append(data_point)\n",
    "                data_point=[]\n",
    "                tot_tweets=0\n",
    "                usr_set={None}\n",
    "\n",
    "                for index2, row2 in data.iloc[index:,:].iterrows():\n",
    "                    try:\n",
    "                        row2['tweet_created_at'].date()\n",
    "                        origin  = row2['tweet_created_at']\n",
    "                        if not c_id<row2['event_id']:\n",
    "                            c_id=row2['event_id']\n",
    "                        break\n",
    "                    except Exception ,e:\n",
    "                        print e\n",
    "                        continue\n",
    "                origin=origin + timedelta(minutes=time_gap_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2013-08-23</th>\n",
       "      <th>5</th>\n",
       "      <th>1124</th>\n",
       "      <th>harassment;sexual;mayor;filner;san</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-08-24</td>\n",
       "      <td>2</td>\n",
       "      <td>5209</td>\n",
       "      <td>panda;birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-08-24</td>\n",
       "      <td>4</td>\n",
       "      <td>13287</td>\n",
       "      <td>francisco;mayor;emergency;san</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-08-24</td>\n",
       "      <td>2</td>\n",
       "      <td>8307</td>\n",
       "      <td>anniversary;50th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2013-08-24</td>\n",
       "      <td>2</td>\n",
       "      <td>12488</td>\n",
       "      <td>wildfire;yosemite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2013-08-24</td>\n",
       "      <td>2</td>\n",
       "      <td>3311</td>\n",
       "      <td>website;dhs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2013-08-23  5   1124 harassment;sexual;mayor;filner;san\n",
       "0  2  2013-08-24  2   5209                        panda;birth\n",
       "1  3  2013-08-24  4  13287      francisco;mayor;emergency;san\n",
       "2  4  2013-08-24  2   8307                   anniversary;50th\n",
       "3  5  2013-08-24  2  12488                  wildfire;yosemite\n",
       "4  6  2013-08-24  2   3311                        website;dhs"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('input/events.csv', lineterminator='\\n')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 10, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xx = np.array(X,dtype=float)\n",
    "Xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data2.iloc[:107,3]\n",
    "Yy=np.array(Y)\n",
    "Yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26.  42.  63.  81. 103. 122. 136. 152. 167. 174.]\n",
      "[26. 16. 21. 18. 22. 19. 14. 16. 15.  7.]\n",
      "[26. 16. 21. 18. 22. 19. 14. 16. 15.  7.]\n",
      "[0. 1. 0. 2. 2. 1. 1. 3. 1. 1.]\n",
      "[26. 15. 21. 16. 20. 18. 13. 13. 14.  6.]\n",
      "[ 82797. 135707. 124457. 649255.  17828. 103296. 101078. 445979. 106361.\n",
      "  28409.]\n",
      "[1106.   18.   59.   10.   24.   35.   63.   51.   40.   57.]\n",
      "[25. 16. 20. 18. 22. 17. 13. 16. 14.  7.]\n",
      "[1058238.  318787.  232154.  115956.   49970.  685759.  255468.  306797.\n",
      "  450632.   29227.]\n",
      "[500. 229. 343. 281. 408. 302. 250. 271. 281. 128.]\n",
      "[1584. 1588. 1595. 1597. 1598. 1601. 1606. 1607. 1612. 1617.]\n",
      "[1.41e+03 4.00e+00 7.00e+00 2.00e+00 1.00e+00 3.00e+00 5.00e+00 1.00e+00\n",
      " 5.00e+00 5.00e+00]\n",
      "[1.41e+03 4.00e+00 7.00e+00 2.00e+00 1.00e+00 3.00e+00 5.00e+00 1.00e+00\n",
      " 5.00e+00 5.00e+00]\n",
      "[132.   0.   2.   0.   0.   0.   1.   0.   0.   2.]\n",
      "[1.278e+03 4.000e+00 5.000e+00 2.000e+00 1.000e+00 3.000e+00 4.000e+00\n",
      " 1.000e+00 5.000e+00 3.000e+00]\n",
      "[6.394992e+07 1.585000e+03 1.171200e+04 6.387000e+03 1.410000e+02\n",
      " 3.146900e+04 1.148900e+04 2.470000e+02 1.051800e+04 3.853000e+03]\n",
      "[2.0871e+04 5.0000e+01 8.0000e+00 5.0000e+00 0.0000e+00 1.0000e+01\n",
      " 1.2000e+01 0.0000e+00 5.4000e+01 2.5000e+02]\n",
      "[1.29e+03 4.00e+00 6.00e+00 2.00e+00 1.00e+00 2.00e+00 4.00e+00 1.00e+00\n",
      " 4.00e+00 5.00e+00]\n",
      "[1.8873813e+07 1.4037900e+05 3.9172000e+04 8.4330000e+03 1.0000000e+00\n",
      " 9.5985000e+04 1.3272800e+05 2.5300000e+02 3.4043000e+04 6.3190000e+03]\n",
      "[2.264e+04 6.100e+01 1.040e+02 2.300e+01 1.400e+01 5.400e+01 8.100e+01\n",
      " 2.500e+01 9.900e+01 8.400e+01]\n",
      "[2761. 2817. 2859. 2908. 2951. 2992. 3032. 3079. 3119. 3149.]\n",
      "[1144.   56.   42.   49.   43.   41.   40.   47.   40.   30.]\n",
      "[1144.   56.   42.   49.   43.   41.   40.   47.   40.   30.]\n",
      "[247.  12.  11.  12.   5.  10.   8.   6.   7.  11.]\n",
      "[897.  44.  31.  37.  38.  31.  32.  41.  33.  19.]\n",
      "[1.79842652e+08 4.29368000e+05 3.64273000e+05 5.35500000e+05\n",
      " 2.39343000e+05 4.26678400e+06 1.03601000e+05 3.20955000e+05\n",
      " 1.05733210e+07 2.83160000e+04]\n",
      "[24681.  1788.   993.   940.   888.   635.   489.   543.   366.   830.]\n",
      "[1103.   54.   36.   46.   39.   39.   38.   47.   40.   29.]\n",
      "[15557368.   584717.   692087.   463704.   814078.   282330.   199178.\n",
      "   467534.   554977.   113400.]\n",
      "[18269.   890.   596.   804.   661.   601.   634.   729.   525.   456.]\n",
      "[3177. 3177. 3177. 3177. 3177. 3177. 3177. 3177. 3177. 3177.]\n",
      "[28.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[28.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[6. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[22.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[215527.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "      0.]\n",
      "[646.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[26.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[425292.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "      0.]\n",
      "[410.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[6866. 6868. 6872. 6877. 6880. 6881. 6882. 6883. 6888. 6889.]\n",
      "[3.689e+03 2.000e+00 4.000e+00 5.000e+00 3.000e+00 1.000e+00 1.000e+00\n",
      " 1.000e+00 5.000e+00 1.000e+00]\n",
      "[3.689e+03 2.000e+00 4.000e+00 5.000e+00 3.000e+00 1.000e+00 1.000e+00\n",
      " 1.000e+00 5.000e+00 1.000e+00]\n",
      "[1.382e+03 1.000e+00 2.000e+00 2.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00]\n",
      "[2.307e+03 1.000e+00 2.000e+00 3.000e+00 2.000e+00 1.000e+00 1.000e+00\n",
      " 1.000e+00 4.000e+00 1.000e+00]\n",
      "[9.9154347e+07 2.8622000e+04 1.0880000e+03 2.2130000e+03 6.8000000e+03\n",
      " 1.5390000e+03 4.7030000e+03 1.3880000e+03 8.4140000e+03 8.7600000e+02]\n",
      "[5.1689e+04 6.0000e+01 1.3700e+02 1.8100e+02 1.7000e+01 6.0000e+01\n",
      " 6.0000e+01 9.0000e+00 1.8000e+02 6.0000e+01]\n",
      "[3.632e+03 2.000e+00 4.000e+00 4.000e+00 3.000e+00 1.000e+00 1.000e+00\n",
      " 1.000e+00 4.000e+00 1.000e+00]\n",
      "[3.7607392e+07 6.2310000e+03 2.2197400e+05 1.2802100e+05 9.0800000e+02\n",
      " 4.9500000e+03 1.6300000e+03 9.0580000e+03 2.4399000e+04 1.4561000e+04]\n",
      "[5.0261e+04 3.2000e+01 7.2000e+01 9.4000e+01 5.3000e+01 2.3000e+01\n",
      " 2.3000e+01 1.7000e+01 9.9000e+01 2.3000e+01]\n",
      "[8442. 8442. 8442. 8442. 8442. 8442. 8442. 8442. 8442. 8442.]\n",
      "[1553.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[1553.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[437.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[1116.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[11036228.        0.        0.        0.        0.        0.        0.\n",
      "        0.        0.        0.]\n",
      "[9079.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[1533.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[30604585.        0.        0.        0.        0.        0.        0.\n",
      "        0.        0.        0.]\n",
      "[25192.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      "[9010. 9010. 9010. 9010. 9010. 9010. 9010. 9010. 9010. 9010.]\n",
      "[568.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[568.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[299.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[269.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[11718897.        0.        0.        0.        0.        0.        0.\n",
      "        0.        0.        0.]\n",
      "[1674.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[562.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[2940762.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[9035.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[9010. 9010. 9010. 9010. 9010. 9010. 9010. 9010. 9010. 9010.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[9095. 9095. 9095. 9095. 9095. 9095. 9095. 9095. 9095. 9095.]\n",
      "[85.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[85.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[16.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[69.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[486564.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "      0.]\n",
      "[1277.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[84.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[1157958.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[1591.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[9120. 9129. 9145. 9157. 9174. 9184. 9192. 9202. 9211. 9217.]\n",
      "[25.  9. 16. 12. 17. 10.  8. 10.  9.  6.]\n",
      "[25.  9. 16. 12. 17. 10.  8. 10.  9.  6.]\n",
      "[4. 0. 0. 1. 1. 0. 0. 0. 0. 2.]\n",
      "[21.  9. 16. 11. 16. 10.  8. 10.  9.  4.]\n",
      "[537017.  87382.  17602. 134804. 131306.  16958.   7691.  23868.   8740.\n",
      "   2560.]\n",
      "[1.410e+02 8.500e+01 1.670e+02 4.102e+04 1.056e+04 2.000e+00 1.000e+00\n",
      " 3.000e+00 2.000e+00 2.000e+00]\n",
      "[19.  7. 13.  9.  9.  9.  7.  6.  9.  5.]\n",
      "[337279.  84593. 331124. 131055. 344689.  88158.  87610. 210879.  36876.\n",
      "  21260.]\n",
      "[401. 144. 267. 223. 314. 213. 116. 167. 150. 103.]\n",
      "[11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329.]\n",
      "[2112.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[2112.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[1132.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[980.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[78726003.        0.        0.        0.        0.        0.        0.\n",
      "        0.        0.        0.]\n",
      "[6596.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[2091.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[9492751.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[33173.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      "[11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329. 11329.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[12353. 12353. 12353. 12353. 12353. 12353. 12353. 12353. 12353. 12353.]\n",
      "[1024.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[1024.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[219.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[805.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[18147167.        0.        0.        0.        0.        0.        0.\n",
      "        0.        0.        0.]\n",
      "[29421.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      "[993.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[17004264.        0.        0.        0.        0.        0.        0.\n",
      "        0.        0.        0.]\n",
      "[18030.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      "[14001. 14025. 14040. 14067. 14097. 14116. 14129. 14143. 14152. 14177.]\n",
      "[1648.   24.   15.   27.   30.   19.   13.   14.    9.   25.]\n",
      "[1648.   24.   15.   27.   30.   19.   13.   14.    9.   25.]\n",
      "[589.   6.   6.  11.  14.   9.   3.  10.   2.   8.]\n",
      "[1059.   18.    9.   16.   16.   10.   10.    4.    7.   17.]\n",
      "[6.5366726e+07 5.7090000e+04 2.8181000e+04 1.1522300e+05 1.4162100e+05\n",
      " 5.6407050e+06 8.6399000e+04 3.7270000e+03 1.0038500e+05 5.7230500e+05]\n",
      "[105568.    753.    406.    748.    651.    789.    198.    157.    258.\n",
      "   1602.]\n",
      "[1596.   24.   15.   27.   30.   19.   13.   14.    9.   25.]\n",
      "[3.4400484e+07 3.3454100e+05 2.3434000e+05 2.6949700e+05 2.9077300e+05\n",
      " 1.7237500e+05 1.3721500e+05 3.4234000e+04 3.1259900e+05 5.3417600e+05]\n",
      "[28215.   396.   238.   467.   494.   315.   230.   208.   143.   404.]\n",
      "[14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188.]\n",
      "[11.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[11.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[3. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[8. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[25718.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      "[144.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[11.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[39346.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      "[179.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188. 14188.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[14562. 14562. 14562. 14562. 14562. 14562. 14562. 14562. 14562. 14562.]\n",
      "[374.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[374.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[235.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[139.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[19767014.        0.        0.        0.        0.        0.        0.\n",
      "        0.        0.        0.]\n",
      "[2888.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[372.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[1751093.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[5287.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[14562. 14562. 14562. 14562. 14562. 14562. 14562. 14562. 14562. 14562.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[14562. 14562. 14562. 14562. 14562. 14562. 14562. 14562. 14562. 14562.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[14794. 14794. 14794. 14794. 14794. 14794. 14794. 14794. 14794. 14794.]\n",
      "[232.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[232.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[37.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[195.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[16599834.        0.        0.        0.        0.        0.        0.\n",
      "        0.        0.        0.]\n",
      "[2739.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[223.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[1766865.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[4302.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[14794. 14794. 14794. 14794. 14794. 14794. 14794. 14794. 14794. 14794.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878.]\n",
      "[84.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[84.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[18.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[66.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[1888366.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[245.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[79.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[1650801.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[1432.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878. 14878.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[15245. 15245. 15245. 15245. 15245. 15245. 15245. 15245. 15245. 15245.]\n",
      "[367.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[367.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[169.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[198.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[56231122.        0.        0.        0.        0.        0.        0.\n",
      "        0.        0.        0.]\n",
      "[10596.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      "[359.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[6379213.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[6804.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[15245. 15245. 15245. 15245. 15245. 15245. 15245. 15245. 15245. 15245.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[15252. 15252. 15253. 15255. 15255. 15255. 15256. 15257. 15258. 15258.]\n",
      "[7. 0. 1. 2. 0. 0. 1. 1. 1. 0.]\n",
      "[7. 0. 1. 2. 0. 0. 1. 1. 1. 0.]\n",
      "[7. 0. 0. 2. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0.0000e+00 0.0000e+00 8.5103e+05 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 1.9600e+02 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[7. 0. 1. 2. 0. 0. 1. 1. 1. 0.]\n",
      "[2042.    0.   48.   88.    0.    0.    0.    5.    0.    0.]\n",
      "[135.   0.   9.  21.   0.   0.  10.  20.  12.   0.]\n",
      "[15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782.]\n",
      "[524.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[524.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[302.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[222.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[2507582.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[468.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[507.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[2204428.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[9246.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782. 15782.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16249. 16249. 16249. 16249. 16249. 16249. 16249. 16249. 16249. 16249.]\n",
      "[467.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[467.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[153.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[314.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[33001649.        0.        0.        0.        0.        0.        0.\n",
      "        0.        0.        0.]\n",
      "[1998.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[455.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[4575940.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[8355.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[16249. 16249. 16249. 16249. 16249. 16249. 16249. 16249. 16249. 16249.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[151.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[151.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[39.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[112.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[3523183.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[746.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[141.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[2331321.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[2567.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400. 16400.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571.]\n",
      "[171.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[171.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[20.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[151.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[366396.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "      0.]\n",
      "[1436.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[157.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[1980621.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[2591.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571. 16571.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16745. 16745. 16745. 16745. 16745. 16745. 16745. 16745. 16745. 16745.]\n",
      "[174.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[174.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[15.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[159.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[2244679.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[2232.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[165.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[1316506.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[3342.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[16745. 16745. 16745. 16745. 16745. 16745. 16745. 16745. 16745. 16745.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16745. 16745. 16745. 16745. 16745. 16745. 16745. 16745. 16745. 16745.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16758. 16758. 16758. 16758. 16758. 16758. 16758. 16758. 16758. 16758.]\n",
      "[13.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[13.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[2. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[11.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[255720.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "      0.]\n",
      "[97.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[13.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[183471.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "      0.]\n",
      "[202.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[16758. 16758. 16758. 16758. 16758. 16758. 16758. 16758. 16758. 16758.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843.]\n",
      "[85.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[85.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[2. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[83.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[506331.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "      0.]\n",
      "[506.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[59.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[623541.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "      0.]\n",
      "[1687.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843. 16843.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16927. 16927. 16927. 16927. 16927. 16927. 16927. 16927. 16927. 16927.]\n",
      "[84.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[84.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[35.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[49.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[93340.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      "[2760.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[81.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[498062.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "      0.]\n",
      "[1482.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[16927. 16927. 16927. 16927. 16927. 16927. 16927. 16927. 16927. 16927.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[16927. 16927. 16927. 16927. 16927. 16927. 16927. 16927. 16927. 16927.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[414.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[414.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[169.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[245.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[2271264.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[2501.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[411.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[1135855.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.]\n",
      "[7166.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341. 17341.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "zero occurd\n"
     ]
    }
   ],
   "source": [
    "for i in range(107):\n",
    "    for j in range(10):\n",
    "        print Xx[i,:,j]\n",
    "        if np.abs(Xx[i,:,j]).max(axis = 0)==0:\n",
    "            print \"zero occurd\"\n",
    "        if np.isnan(Xx[i,:,j]).any():\n",
    "            print \"is nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bawa/anaconda3/envs/FYP/lib/python2.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(107):\n",
    "    for j in range(10):\n",
    "        Xx[i,:,j] = Xx[i,:,j]/np.abs(Xx[i,:,j]).max(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_single= Xx[:90,]\n",
    "y_train_single= Yy[:90,]\n",
    "x_val_single= Xx[90:,]\n",
    "y_val_single= Yy[90:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 10, 10)\n",
      "(90,)\n"
     ]
    }
   ],
   "source": [
    "print x_train_single.shape\n",
    "print y_train_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "BUFFER_SIZE = 20\n",
    "EVALUATION_INTERVAL = 1\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))\n",
    "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))\n",
    "val_data_single = val_data_single.batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.LSTM object at 0x7f9fc24c40d0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "WARNING:tensorflow:From /home/bawa/anaconda3/envs/FYP/lib/python2.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "single_step_model = tf.keras.models.Sequential()\n",
    "single_step_model.add(tf.keras.layers.LSTM(50,\n",
    "                                           input_shape=x_train_single.shape[-2:]))\n",
    "single_step_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "single_step_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mae')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From /home/bawa/anaconda3/envs/FYP/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "5/5 [==============================] - 0s 28ms/step - loss: nan\n",
      "1/1 [==============================] - 4s 4s/step - loss: nan - val_loss: nan\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 114ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 118ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 115ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 115ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 116ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 118ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 115ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 114ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 116ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 115ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 117ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 119ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 117ms/step - loss: nan - val_loss: nan\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 129ms/step - loss: nan - val_loss: nan\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 135ms/step - loss: nan - val_loss: nan\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - val_loss: nan\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 116ms/step - loss: nan - val_loss: nan\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - val_loss: nan\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 139ms/step - loss: nan - val_loss: nan\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 118ms/step - loss: nan - val_loss: nan\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 117ms/step - loss: nan - val_loss: nan\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - val_loss: nan\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 121ms/step - loss: nan - val_loss: nan\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 136ms/step - loss: nan - val_loss: nan\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - val_loss: nan\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 127ms/step - loss: nan - val_loss: nan\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 151ms/step - loss: nan - val_loss: nan\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 134ms/step - loss: nan - val_loss: nan\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 127ms/step - loss: nan - val_loss: nan\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - val_loss: nan\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 129ms/step - loss: nan - val_loss: nan\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - val_loss: nan\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 127ms/step - loss: nan - val_loss: nan\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - val_loss: nan\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - val_loss: nan\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 129ms/step - loss: nan - val_loss: nan\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 125ms/step - loss: nan - val_loss: nan\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 187ms/step - loss: nan - val_loss: nan\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 166ms/step - loss: nan - val_loss: nan\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 146ms/step - loss: nan - val_loss: nan\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 143ms/step - loss: nan - val_loss: nan\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 139ms/step - loss: nan - val_loss: nan\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 130ms/step - loss: nan - val_loss: nan\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 131ms/step - loss: nan - val_loss: nan\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - val_loss: nan\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 139ms/step - loss: nan - val_loss: nan\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 121ms/step - loss: nan - val_loss: nan\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - val_loss: nan\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - val_loss: nan\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - val_loss: nan\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 118ms/step - loss: nan - val_loss: nan\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 127ms/step - loss: nan - val_loss: nan\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 130ms/step - loss: nan - val_loss: nan\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - val_loss: nan\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 133ms/step - loss: nan - val_loss: nan\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - val_loss: nan\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - val_loss: nan\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 114ms/step - loss: nan - val_loss: nan\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 130ms/step - loss: nan - val_loss: nan\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 137ms/step - loss: nan - val_loss: nan\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 205/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - val_loss: nan\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - val_loss: nan\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - val_loss: nan\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 115ms/step - loss: nan - val_loss: nan\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 164ms/step - loss: nan - val_loss: nan\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 159ms/step - loss: nan - val_loss: nan\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 135ms/step - loss: nan - val_loss: nan\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - val_loss: nan\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - val_loss: nan\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - val_loss: nan\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 117ms/step - loss: nan - val_loss: nan\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 127ms/step - loss: nan - val_loss: nan\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 166ms/step - loss: nan - val_loss: nan\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 175ms/step - loss: nan - val_loss: nan\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 126ms/step - loss: nan - val_loss: nan\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 83ms/step - loss: nan - val_loss: nan\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - val_loss: nan\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 114ms/step - loss: nan - val_loss: nan\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - val_loss: nan\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - val_loss: nan\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - val_loss: nan\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 185ms/step - loss: nan - val_loss: nan\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 360/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - val_loss: nan\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - val_loss: nan\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - val_loss: nan\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - val_loss: nan\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - val_loss: nan\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - val_loss: nan\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 115ms/step - loss: nan - val_loss: nan\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - val_loss: nan\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 148ms/step - loss: nan - val_loss: nan\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 119ms/step - loss: nan - val_loss: nan\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 145ms/step - loss: nan - val_loss: nan\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 146ms/step - loss: nan - val_loss: nan\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - val_loss: nan\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - val_loss: nan\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - val_loss: nan\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - val_loss: nan\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - val_loss: nan\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - val_loss: nan\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - val_loss: nan\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 120ms/step - loss: nan - val_loss: nan\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 134ms/step - loss: nan - val_loss: nan\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 142ms/step - loss: nan - val_loss: nan\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 119ms/step - loss: nan - val_loss: nan\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 114ms/step - loss: nan - val_loss: nan\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 134ms/step - loss: nan - val_loss: nan\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 164ms/step - loss: nan - val_loss: nan\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 158ms/step - loss: nan - val_loss: nan\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 157ms/step - loss: nan - val_loss: nan\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 148ms/step - loss: nan - val_loss: nan\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 153ms/step - loss: nan - val_loss: nan\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 140ms/step - loss: nan - val_loss: nan\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 117ms/step - loss: nan - val_loss: nan\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 157ms/step - loss: nan - val_loss: nan\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 151ms/step - loss: nan - val_loss: nan\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - val_loss: nan\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - val_loss: nan\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 114ms/step - loss: nan - val_loss: nan\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - val_loss: nan\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - val_loss: nan\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - val_loss: nan\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 82ms/step - loss: nan - val_loss: nan\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 83ms/step - loss: nan - val_loss: nan\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - val_loss: nan\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - val_loss: nan\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - val_loss: nan\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 83ms/step - loss: nan - val_loss: nan\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - val_loss: nan\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 83ms/step - loss: nan - val_loss: nan\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 82ms/step - loss: nan - val_loss: nan\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - val_loss: nan\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - val_loss: nan\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - val_loss: nan\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - val_loss: nan\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - val_loss: nan\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - val_loss: nan\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 78ms/step - loss: nan - val_loss: nan\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - val_loss: nan\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - val_loss: nan\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 82ms/step - loss: nan - val_loss: nan\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 76ms/step - loss: nan - val_loss: nan\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - val_loss: nan\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - val_loss: nan\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - val_loss: nan\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - val_loss: nan\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - val_loss: nan\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 161ms/step - loss: nan - val_loss: nan\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - val_loss: nan\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - val_loss: nan\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 79ms/step - loss: nan - val_loss: nan\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 78ms/step - loss: nan - val_loss: nan\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 76ms/step - loss: nan - val_loss: nan\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 76ms/step - loss: nan - val_loss: nan\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 76ms/step - loss: nan - val_loss: nan\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 79ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - val_loss: nan\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 76ms/step - loss: nan - val_loss: nan\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - val_loss: nan\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - val_loss: nan\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - val_loss: nan\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - val_loss: nan\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - val_loss: nan\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 76ms/step - loss: nan - val_loss: nan\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - val_loss: nan\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - val_loss: nan\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - val_loss: nan\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - val_loss: nan\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 162ms/step - loss: nan - val_loss: nan\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: nan\n",
      "1/1 [==============================] - 0s 163ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
    "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                            validation_data=val_data_single,\n",
    "                                            validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history, title):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(loss))\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_history(single_step_history,\n",
    "                   'Single Step Training and validation loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "  time_steps = []\n",
    "  for i in range(-length, 0, 1):\n",
    "    time_steps.append(i)\n",
    "  return time_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "  labels = ['History', 'True Future', 'Model Prediction']\n",
    "  marker = ['.-', 'rx', 'go']\n",
    "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
    "  if delta:\n",
    "    future = delta\n",
    "  else:\n",
    "    future = 0\n",
    "\n",
    "  plt.title(title)\n",
    "  for i, x in enumerate(plot_data):\n",
    "    if i:\n",
    "      plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
    "               label=labels[i])\n",
    "    else:\n",
    "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "  plt.legend()\n",
    "  plt.xlim([time_steps[0], (future+5)*2])\n",
    "  plt.xlabel('Time-Step')\n",
    "  return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in val_data_single.take(3):\n",
    "  plot = show_plot([x[0][:, 1].numpy(), y[0].numpy(),\n",
    "                    single_step_model.predict(x.numpy())[0]], 12,\n",
    "                   'Single Step Prediction')\n",
    "  plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
